<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2018-03-27">
  <title>Data Science: Time for Professionalisation?</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@3.9.2/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@3.9.2/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="https://inverseprobability.com/assets/css/talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'https://unpkg.com/reveal.js@3.9.2/css/print/pdf.css' : 'https://unpkg.com/reveal.js@3.9.2/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="https://unpkg.com/reveal.js@3.9.2/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="../assets/js/figure-animate.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Data Science: Time for Professionalisation?</h1>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2018-03-27</time></p>
  <p class="venue" style="text-align:center">LSE Workshop on Data Science Theory and Practice</p>
</section>

<section class="slide level2">

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!-- SECTION What is Machine Learning? -->
</section>
<section id="what-is-machine-learning" class="slide level2">
<h2>What is Machine Learning?</h2>
</section>
<section id="what-is-machine-learning-1" class="slide level2">
<h2>What is Machine Learning?</h2>
<div class="fragment">
<p><span class="math display">\[ \text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}\]</span></p>
</div>
<div class="fragment">
<ul>
<li><strong>data</strong> : observations, could be actively or passively acquired (meta-data).</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>model</strong> : assumptions, based on previous experience (other data! transfer learning etc), or beliefs about the regularities of the universe. Inductive bias.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>prediction</strong> : an action to be taken or a categorization or a quality score.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Royal Society Report: <a href="https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf">Machine Learning: Power and Promise of Computers that Learn by Example</a></li>
</ul>
</div>
</section>
<section id="what-is-machine-learning-2" class="slide level2">
<h2>What is Machine Learning?</h2>
<p><span class="math display">\[\text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}\]</span></p>
<ul>
<li class="fragment">To combine data with a model need:</li>
<li class="fragment"><strong>a prediction function</strong> <span class="math inline">\(f(\cdot)\)</span> includes our beliefs about the regularities of the universe</li>
<li class="fragment"><strong>an objective function</strong> <span class="math inline">\(E(\cdot)\)</span> defines the cost of misprediction.</li>
</ul>
</section>
<section id="machine-learning" class="slide level2">
<h2>Machine Learning</h2>
<ul>
<li>Driver of two different domains:
<ol type="1">
<li><em>Data Science</em>: arises from the fact that we now capture data by happenstance.</li>
<li><em>Artificial Intelligence</em>: emulation of human behaviour.</li>
</ol></li>
<li>Connection: Internet of Things</li>
</ul>
</section>
<section id="machine-learning-1" class="slide level2">
<h2>Machine Learning</h2>
<ul>
<li>Driver of two different domains:
<ol type="1">
<li><em>Data Science</em>: arises from the fact that we now capture data by happenstance.</li>
<li><em>Artificial Intelligence</em>: emulation of human behaviour.</li>
</ol></li>
<li>Connection: Internet of <del>Things</del></li>
</ul>
</section>
<section id="machine-learning-2" class="slide level2">
<h2>Machine Learning</h2>
<ul>
<li>Driver of two different domains:
<ol type="1">
<li><em>Data Science</em>: arises from the fact that we now capture data by happenstance.</li>
<li><em>Artificial Intelligence</em>: emulation of human behaviour.</li>
</ol></li>
<li>Connection: Internet of People</li>
</ul>
</section>
<section id="section" class="slide level2">
<h2></h2>
<center>
Convention for the Protection of <em>Individuals</em> with regard to Automatic Processing of <em>Personal Data</em> (1981/1/28)
</center>
</section>
<section id="what-does-machine-learning-do" class="slide level2">
<h2>What does Machine Learning do?</h2>
<ul>
<li>ML Automates through Data
<ul>
<li><em>Strongly</em> related to statistics.</li>
<li>Field underpins revolution in <em>data science</em> and <em>AI</em></li>
</ul></li>
<li>With AI:
<ul>
<li><em>logic</em>, <em>robotics</em>, <em>computer vision</em>, <em>speech</em></li>
</ul></li>
<li>With Data Science:
<ul>
<li><em>databases</em>, <em>data mining</em>, <em>statistics</em>, <em>visualization</em></li>
</ul></li>
</ul>
</section>
<section id="embodiment-factors" class="slide level2">
<h2>Embodiment Factors</h2>
<div class="figure">
<div id="embodiment-factors-table-figure" class="figure-frame">
<table>
<tr>
<td>
</td>
<td align="center">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//computer.svg" width="60%" style=" ">
</object>
</td>
<td align="center">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//human.svg" width="60%" style=" ">
</object>
</td>
</tr>
<tr>
<td>
bits/min
</td>
<td align="center">
billions
</td>
<td align="center">
2,000
</td>
</tr>
<tr>
<td>
billion<br>calculations/s
</td>
<td align="center">
~100
</td>
<td align="center">
a billion
</td>
</tr>
<tr>
<td>
embodiment
</td>
<td align="center">
20 minutes
</td>
<td align="center">
5 billion years
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
Embodiment factors are the ratio between our ability to compute and our ability to communicate. Relative to the machine we are also locked in. In the table we represent embodiment as the length of time it would take to communicate one second’s worth of computation. For computers it is a matter of minutes, but for a human, it is a matter of thousands of millions of years. See also “Living Together: Mind and Machine Intelligence” <span class="citation" data-cites="Lawrence:embodiment17">Lawrence (2017a)</span>
</aside>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="figure">
<div id="lotus-49-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//Lotus_49-2.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
The Lotus 49, view from the rear. The Lotus 49 was one of the last Formula One cars before the introduction of aerodynamic aids.
</aside>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<div class="figure">
<div id="marcel-renault-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//640px-Marcel_Renault_1903.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Marcel Renault races a Renault 40 cv during the Paris-Madrid race, an early Grand Prix, in 1903. Marcel died later in the race after missing a warning flag for a sharp corner at Couhé Vérac, likely due to dust reducing visibility.
</aside>
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<div class="figure">
<div id="caleb-mcduff-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//Caleb_McDuff_WIX_Silence_Racing_livery.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Caleb McDuff driving for WIX Silence Racing.
</aside>
<!-- SECTION Evolved Relationship with Information -->
</section>
<section id="evolved-relationship-with-information" class="slide level2">
<h2>Evolved Relationship with Information</h2>
</section>
<section id="new-flow-of-information" class="slide level2">
<h2>New Flow of Information</h2>
<div class="figure">
<div id="new-flow-of-information-1-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//data-science/new-flow-of-information001.svg" width="70%" style=" ">
</object>
</div>
</div>
<aside class="notes">
</aside>
</section>
<section id="evolved-relationship" class="slide level2">
<h2>Evolved Relationship</h2>
<div class="figure">
<div id="new-flow-of-information-2-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//data-science/new-flow-of-information002.svg" width="70%" style=" ">
</object>
</div>
</div>
<aside class="notes">
</aside>
</section>
<section id="evolved-relationship-1" class="slide level2">
<h2>Evolved Relationship</h2>
<div class="figure">
<div id="new-flow-of-information-3-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//data-science/new-flow-of-information003.svg" width="70%" style=" ">
</object>
</div>
</div>
<aside class="notes">
The trinity of human, data and computer, and highlights the modern phenomenon. The communication channel between computer and data now has an extremely high bandwidth. The channel between human and computer and the channel between data and human is narrow. New direction of information flow, information is reaching us mediated by the computer. The focus on classical statistics reflected the importance of the direct communication between human and data. The modern challenges of data science emerge when that relationship is being mediated by the machine.
</aside>
</section>
<section id="what-does-machine-learning-do-1" class="slide level2">
<h2>What does Machine Learning do?</h2>
<ul>
<li>Automation scales by codifying processes and automating them.</li>
<li>Need:
<ul>
<li>Interconnected components</li>
<li>Compatible components</li>
</ul></li>
<li>Early examples:
<ul>
<li>cf Colt 45, Ford Model T</li>
</ul></li>
</ul>
</section>
<section id="codify-through-mathematical-functions" class="slide level2">
<h2>Codify Through Mathematical Functions</h2>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ \text{odds} = \frac{p(\text{bought})}{p(\text{not bought})} \]</span></p>
<p><span class="math display">\[ \log \text{odds}  = \beta_0 + \beta_1 \text{age} + \beta_2 \text{latitude}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-1" class="slide level2">
<h2>Codify Through Mathematical Functions</h2>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ p(\text{bought}) =  \sigma\left(\beta_0 + \beta_1 \text{age} + \beta_2 \text{latitude}\right).\]</span></p>
</section>
<section id="codify-through-mathematical-functions-2" class="slide level2">
<h2>Codify Through Mathematical Functions</h2>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ p(\text{bought}) =  \sigma\left(\boldsymbol{\beta}^\top \mathbf{ x}\right).\]</span></p>
</section>
<section id="codify-through-mathematical-functions-3" class="slide level2">
<h2>Codify Through Mathematical Functions</h2>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ y=  f\left(\mathbf{ x}, \boldsymbol{\beta}\right).\]</span></p>
<div class="fragment">
<p>We call <span class="math inline">\(f(\cdot)\)</span> the <em>prediction function</em>.</p>
</div>
</section>
<section id="fit-to-data" class="slide level2">
<h2>Fit to Data</h2>
<ul>
<li>Use an objective function</li>
</ul>
<p><span class="math display">\[E(\boldsymbol{\beta}, \mathbf{Y}, \mathbf{X})\]</span></p>
<div class="fragment">
<ul>
<li>E.g. least squares <span class="math display">\[E(\boldsymbol{\beta}, \mathbf{Y}, \mathbf{X}) = \sum_{i=1}^n\left(y_i - f(\mathbf{ x}_i, \boldsymbol{\beta})\right)^2.\]</span></li>
</ul>
</div>
</section>
<section id="two-components" class="slide level2">
<h2>Two Components</h2>
<ul>
<li>Prediction function, <span class="math inline">\(f(\cdot)\)</span></li>
<li>Objective function, <span class="math inline">\(E(\cdot)\)</span></li>
</ul>
<!-- SECTION Deep Learning -->
</section>
<section id="deep-learning" class="slide level2">
<h2>Deep Learning</h2>
</section>
<section id="deep-learning-1" class="slide level2">
<h2>Deep Learning</h2>
<ul>
<li><p>These are interpretable models: vital for disease modeling etc.</p></li>
<li><p>Modern machine learning methods are less interpretable</p></li>
<li><p>Example: face recognition</p></li>
</ul>
<!-- No slide titles in this context -->
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<p><span class="fragment fade-in"><small>Outline of the DeepFace architecture. A front-end of a single convolution-pooling-convolution filtering on the rectified input, followed by three locally-connected layers and two fully-connected layers. Color illustrates feature maps produced at each layer. The net includes more than 120 million parameters, where more than 95% come from the local and fully connected.</small></span></p>
<div class="figure">
<div id="deep-face-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//deepface_neg.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
The DeepFace architecture <span class="citation" data-cites="Taigman:deepface14">(Taigman et al., 2014)</span>, visualized through colors to represent the functional mappings at each layer. There are 120 million parameters in the model.
</aside>
<div style="text-align:right">
<small>Source: DeepFace <span class="citation" data-cites="Taigman:deepface14">(Taigman et al., 2014)</span></small>
</div>
</section>
<section id="section-5" class="slide level2">
<h2></h2>
<div class="figure">
<div id="early-pinball-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//576px-Early_Pinball.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Deep learning models are composition of simple functions. We can think of a pinball machine as an analogy. Each layer of pins corresponds to one of the layers of functions in the model. Input data is represented by the location of the ball from left to right when it is dropped in from the top. Output class comes from the position of the ball as it leaves the pins at the bottom.
</aside>
</section>
<section id="section-6" class="slide level2">
<h2></h2>
<div class="figure">
<div id="pinball-initialization-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//pinball001.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
At initialization, the pins, which represent the parameters of the function, aren’t in the right place to bring the balls to the correct decisions.
</aside>
</section>
<section id="section-7" class="slide level2">
<h2></h2>
<div class="figure">
<div id="pinball-trained-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//pinball002.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
After learning the pins are now in the right place to bring the balls to the correct decisions.
</aside>
</section>
<section id="data-science-and-professionalisation" class="slide level2">
<h2>Data Science and Professionalisation</h2>
<ul>
<li>Industrial Revolution 4.0?</li>
<li><em>Industrial Revolution</em> (1760-1840) term coined by Arnold Toynbee (1852-1883).</li>
<li>Maybe: But this one is dominated by <em>data</em> not <em>capital</em></li>
<li>A revolution in <em>information</em> rather than <em>energy</em>.</li>
<li>That presents <em>challenges</em> and <em>opportunities</em></li>
<li>Consider Apple vs Nokia: How you handle disruption.</li>
</ul>
<p>compare <a href="https://www.theguardian.com/media-network/2015/mar/05/digital-oligarchy-algorithms-personal-data">digital oligarchy</a> vs <a href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information">how Africa can benefit from the data revolution</a></p>
</section>
<section id="a-time-for-professionalisation" class="slide level2">
<h2>A Time for Professionalisation?</h2>
<ul>
<li>New technologies historically led to new professions:
<ul>
<li>Brunel (born 1806): Civil, mechanical, naval</li>
<li>Tesla (born 1856): Electrical and power</li>
<li>William Shockley (born 1910): Electronic</li>
<li>Watts S. Humphrey (born 1927): Software</li>
</ul></li>
</ul>
</section>
<section id="why" class="slide level2">
<h2>Why?</h2>
<ul>
<li>Codification of best practice.</li>
<li>Developing trust</li>
</ul>
</section>
<section id="where-are-we" class="slide level2">
<h2>Where are we?</h2>
<ul>
<li>Perhaps around the 1980s of programming.
<ul>
<li>We understand <code>if</code>, <code>for</code>, and procedures</li>
<li>But we don’t share best practice.</li>
</ul></li>
<li>Let’s <em>avoid</em> the over formalisation of software engineering.</li>
</ul>
</section>
<section id="the-software-crisis" class="slide level2">
<h2>The Software Crisis</h2>
<p><small></p>
<blockquote>
<p>The major cause of the software crisis is that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming has become an equally gigantic problem.</p>
<p>Edsger Dijkstra (1930-2002), The Humble Programmer</p>
</blockquote>
<p></small></p>
</section>
<section id="the-data-crisis" class="slide level2">
<h2>The Data Crisis</h2>
<p><small></p>
<blockquote>
<p>The major cause of the data crisis is that machines have become more interconnected than ever before. Data access is therefore cheap, but data quality is often poor. What we need is cheap high-quality data. That implies that we develop processes for improving and verifying data quality that are efficient.</p>
<p>There would seem to be two ways for improving efficiency. Firstly, we should not duplicate work. Secondly, where possible we should automate work.</p>
<p>Me </small></p>
</blockquote>
</section>
<section id="rest-of-this-talk-two-areas-of-focus" class="slide level2">
<h2>Rest of this Talk: Two Areas of Focus</h2>
<ul>
<li><p>Reusability of Data</p></li>
<li><p>Deployment of Machine Learning Systems</p></li>
</ul>
</section>
<section id="data-readiness-levels" class="slide level2">
<h2>Data Readiness Levels</h2>
</section>
<section id="data-readiness-levels-1" class="slide level2">
<h2>Data Readiness Levels</h2>
<div class="centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//data-science/data-readiness-levels.png" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><a href="https://arxiv.org/pdf/1705.02245.pdf" class="uri">https://arxiv.org/pdf/1705.02245.pdf</a> <a href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data Readiness Levels</a> <span class="citation" data-cites="Lawrence-drl17">(Lawrence, 2017b)</span></p>
</section>
<section id="three-grades-of-data-readiness" class="slide level2">
<h2>Three Grades of Data Readiness</h2>
<ul>
<li>Grade C - accessibility
<ul>
<li>Transition: data becomes electronically available</li>
</ul></li>
<li>Grade B - validity
<ul>
<li>Transition: pose a question to the data.</li>
</ul></li>
<li>Grade A - usability</li>
</ul>
</section>
<section id="accessibility-grade-c" class="slide level2">
<h2>Accessibility: Grade C</h2>
<ul>
<li><em>Hearsay</em> data.</li>
<li>Availability, is it actually being recorded?</li>
<li>privacy or legal constraints on the accessibility of the recorded data, have ethical constraints been alleviated?</li>
<li>Format: log books, PDF …</li>
<li>limitations on access due to topology (e.g. it’s distributed across a number of devices)</li>
<li>At the end of Grade C data is ready to be loaded into analysis software (R, SPSS, Matlab, Python, Mathematica)</li>
</ul>
</section>
<section id="validity-grade-b" class="slide level2">
<h2>Validity: Grade B</h2>
<ul>
<li>faithfulness and representation</li>
<li>visualisations.</li>
<li>exploratory data analysis</li>
<li>noise characterisation.</li>
</ul>
</section>
<section id="grade-b-checks" class="slide level2">
<h2>Grade B Checks</h2>
<ul>
<li>Missing values.</li>
<li>Schema alignment, record linkage, data fusion</li>
<li>Example:
<ul>
<li>Was a column or columns accidentally perturbed (e.g. through a sort operation that missed one or more columns)? Or was a <a href="http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-5-80">gene name accidentally converted to a date</a>?</li>
</ul></li>
</ul>
</section>
<section id="grade-b-transition" class="slide level2">
<h2>Grade B Transition</h2>
<ul>
<li>At the end of Grade B, ready to define a <em>task</em>, or <em>question</em></li>
<li>Compare with classical statistics:
<ul>
<li><em>Classically</em>: question is first data comes later.</li>
<li><em>Today</em>: data is first question comes later.</li>
</ul></li>
</ul>
</section>
<section id="data-first" class="slide level2">
<h2>Data First</h2>
<p>In a <em>data first</em> company teams own their data quality issues at least as far as grade B1.</p>
</section>
<section id="usability-grade-a" class="slide level2">
<h2>Usability: Grade A</h2>
<ul>
<li>The <em>usability</em> of data
<ul>
<li>Grade A is about data in context.</li>
</ul></li>
<li>Consider appropriateness of a given data set to answer a particular question or to be subject to a particular analysis.</li>
</ul>
</section>
<section id="recursive-effects" class="slide level2">
<h2>Recursive Effects</h2>
<ul>
<li>Grade A may also require:
<ul>
<li>data integration</li>
<li>active collection of new data.</li>
<li>rebalancing of data to ensure fairness</li>
<li>annotation of data by human experts</li>
<li>revisiting the collection (and running through the appropriate stages again)</li>
</ul></li>
</ul>
</section>
<section id="a1-data" class="slide level2">
<h2>A1 Data</h2>
<ul>
<li>A1 data is ready to make available for <em>challenges</em> or <em>AutoML</em> platforms.</li>
</ul>
</section>
<section id="contribute" class="slide level2">
<h2>Contribute!</h2>
<center>
<a href="http://data-readiness.org" class="uri">http://data-readiness.org</a>
</center>
</section>
<section id="also" class="slide level2">
<h2>Also …</h2>
<ul>
<li>Encourage greater interaction between application domains and data scientists</li>
<li>Encourage <em>visualization</em> of data</li>
</ul>
<!-- SECTION Assessing the Organizations Readiness -->
</section>
<section id="assessing-the-organizations-readiness" class="slide level2">
<h2>Assessing the Organizations Readiness</h2>
</section>
<section id="see-also" class="slide level2">
<h2>See Also …</h2>
<ul>
<li>Data Joel Tests
<ul>
<li><a href="https://medium.com/@damoncivin/the-joel-test-for-data-readiness-4882aae64753">proposal by Damon Civin</a> and</li>
<li><a href="https://blog.dominodatalab.com/joel-test-data-science/">proposal by Nick Elprin</a></li>
</ul></li>
</ul>
</section>
<section id="deploying-artificial-intelligence" class="slide level2">
<h2>Deploying Artificial Intelligence</h2>
<ul>
<li>Challenges in deploying AI.</li>
<li>Currently this is in the form of “machine learning systems”</li>
</ul>
</section>
<section id="internet-of-people" class="slide level2">
<h2>Internet of People</h2>
<ul>
<li>Fog computing: barrier between cloud and device blurring.
<ul>
<li>Computing on the Edge</li>
</ul></li>
<li>Complex feedback between algorithm and implementation</li>
</ul>
</section>
<section id="deploying-ml-in-real-world-machine-learning-systems-design" class="slide level2">
<h2>Deploying ML in Real World: Machine Learning Systems Design</h2>
<ul>
<li>Major new challenge for systems designers.</li>
<li>Internet of Intelligence but currently:
<ul>
<li>AI systems are <em>fragile</em></li>
</ul></li>
</ul>
</section>
<section id="machine-learning-systems-design" class="slide level2">
<h2>Machine Learning Systems Design</h2>
<aside class="notes">
But how are we building these AI systems? Predominant technology is machine learning, but those are merely components being injected into a system.
</aside>
</section>
<section id="fragility-of-ai-systems" class="slide level2">
<h2>Fragility of AI Systems</h2>
<ul>
<li>They are componentwise built from ML Capabilities.</li>
<li>Each capability is independently constructed and verified.
<ul>
<li>Pedestrian detection</li>
<li>Road line detection</li>
</ul></li>
<li>Important for verification purposes.</li>
</ul>
<aside class="notes">
Our current AI systems are composed of components that often have machine learning algorithms at the core (or they may have an OR model, or an economics model or even a logic model).
</aside>
</section>
<section id="pigeonholing" class="slide level2">
<h2>Pigeonholing</h2>
<div class="figure">
<div id="too-many-pigeons-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//TooManyPigeons.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Decompartmentalization of the model into parts can be seen as pigeonholing the separate tasks that are required.
</aside>
</section>
<section id="robust" class="slide level2">
<h2>Robust</h2>
<ul>
<li>Need to move beyond pigeonholing tasks.</li>
<li>Need new approaches to both the design of the individual components, and the combination of components within our AI systems.</li>
</ul>
</section>
<section id="rapid-reimplementation" class="slide level2">
<h2>Rapid Reimplementation</h2>
<ul>
<li>Whole systems are being deployed.</li>
<li>But they change their environment.</li>
<li>The experience evolved adversarial behaviour.</li>
</ul>
</section>
<section id="machine-learning-systems-design-1" class="slide level2">
<h2>Machine Learning Systems Design</h2>
</section>
<section id="section-8" class="slide level2">
<h2></h2>
<div class="figure">
<div id="science-holborn-viaduct-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//science-holborn-viaduct.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Centrifugal governor as held by “Science” on Holborn Viaduct
</aside>
<div class="caption" style="">
Figure: Science on Holborn Viaduct, cradling the Centrifugal Governor.
</div>
<p><a href="http://www.maths.ed.ac.uk/~v1ranick/papers/maxwell1.pdf">On Governors</a>, James Clerk Maxwell 1868</p>
</section>
<section id="section-9" class="slide level2">
<h2></h2>
<div class="figure">
<div id="steam-engine-boulton-watt-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="https://inverseprobability.com/talks/./slides/diagrams//SteamEngine_Boulton&Watt_1784.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Watt’s Steam Engine which made Steam Power Efficient and Practical.
</aside>
</section>
<section id="section-10" class="slide level2">
<h2></h2>
<div class="figure">
<div id="centrifugal-governor-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="https://inverseprobability.com/talks/./slides/diagrams//Centrifugal_governor.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
The centrifugal governor, an early example of a decision making system. The parameters of the governor include the lengths of the linkages (which effect how far the throttle opens in response to movement in the balls), the weight of the balls (which effects inertia) and the limits of to which the balls can rise.
</aside>
</section>
<section id="adversaries" class="slide level2">
<h2>Adversaries</h2>
<ul>
<li>Stuxnet</li>
<li>Mischevious-Adversarial</li>
</ul>
</section>
<section id="an-intelligent-system" class="slide level2">
<h2>An Intelligent System</h2>
<div class="figure">
<div class="figure-frame" id="paolo-save-figure">
<video width="80%" height="" controls preload="none">
<source src="https://inverseprobability.com/talks/./slides/diagrams//personal/paolo-save.mp4" type="video/mp4"/>
</video>
</div>
</div>
<aside class="notes">
An advanced adaptable machine learning system.
</aside>
<div style="text-align:right">
<small>Joint work with M. Milo</small>
</div>
</section>
<section id="an-intelligent-system-1" class="slide level2">
<h2>An Intelligent System</h2>
<div class="figure">
<div class="figure-frame" id="paolo-peppercorn-figure">
<video width="40%" height="" controls preload="none">
<source src="https://inverseprobability.com/talks/./slides/diagrams//personal/paolo-peppercorn.mp4" type="video/mp4"/>
</video>
</div>
</div>
<aside class="notes">
A peppercorn is a system failure that’s the result of designed behavior.
</aside>
<div style="text-align:right">
<small>Joint work with M. Milo</small>
</div>
</section>
<section id="peppercorns" class="slide level2">
<h2>Peppercorns</h2>
<ul>
<li>A new name for system failures which aren’t bugs.</li>
<li>Difference between finding a fly in your soup vs a peppercorn in your soup.</li>
</ul>
</section>
<section id="peppercorns-1" class="slide level2">
<h2>Peppercorns</h2>
<div class="figure">
<div id="peppercorn-siri-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/1y2UKz47gew?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
</div>
<aside class="notes">
A peppercorn is a system design failure which is not a bug, but a conformance to design specification that causes problems when the system is deployed in the real world with mischevious and adversarial actors.
</aside>
</section>
<section id="section-11" class="slide level2">
<h2></h2>
<iframe id="reddit-embed" width="600" height="450" src="https://www.redditmedia.com/r/teslamotors/comments/nrs8kf/you_think_ice_cream_truck_stop_signs_are_a_problem/?ref_source=embed&amp;ref=share&amp;embed=true" sandbox="allow-scripts allow-same-origin allow-popups" frameborder="0" scrolling="no">
</iframe>
</section>
<section id="turnaround-and-update" class="slide level2">
<h2>Turnaround And Update</h2>
<ul>
<li>There is a massive need for turn around and update</li>
<li>A redeploy of the entire system.
<ul>
<li>This involves changing the way we design and deploy.</li>
</ul></li>
<li>Interface between security engineering and machine learning.</li>
</ul>
<!-- SECTION Conclusion -->
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
</section>
<section id="conclusion-1" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li>Artificial Intelligence and Data Science are fundamentally different.</li>
<li>In one you are dealing with data collected by happenstance.</li>
<li>In the other you are trying to build systems in the real world, often by actively collecting data.</li>
<li>Our approaches to systems design are building powerful machines that will be deployed in evolving environments.</li>
</ul>
</section>
<section id="thanks" class="slide level2 scrollable">
<h2 class="scrollable">Thanks!</h2>
<ul>
<li><p>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></p></li>
<li><p>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></p></li>
<li><p>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></p></li>
<li><p>blog posts:</p>
<p><a href="http://inverseprobability.com/2017/07/17/what-is-machine-learning">What is Machine Learning?</a></p>
<p><a href="http://inverseprobability.com/2015/12/04/what-kind-of-ai">System Zero</a></p></li>
<li><p><a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">Andrej Karpathy’s Medium Post</a></p>
<p><a href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data Readiness Levels</a></p>
<p><a href="http://inverseprobability.com/2017/11/15/decision-making">Decision Making and Diversity</a></p>
<p><a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural vs Artifical Intelligence</a></p></li>
<li><p><a href="https://medium.com/@mijordan3/artificial-intelligence-the-revolution-hasnt-happened-yet-5e1d5812e1e7">Mike Jordan’s Medium Post</a></p></li>
</ul>
</section>
<section id="references" class="slide level2 unnumbered scrollable">
<h2 class="unnumbered scrollable">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Lawrence-drl17" class="csl-entry" role="doc-biblioentry">
Lawrence, N.D., 2017b. Data readiness levels. ArXiv.
</div>
<div id="ref-Lawrence:embodiment17" class="csl-entry" role="doc-biblioentry">
Lawrence, N.D., 2017a. Living together: Mind and machine intelligence. arXiv.
</div>
<div id="ref-Taigman:deepface14" class="csl-entry" role="doc-biblioentry">
Taigman, Y., Yang, M., Ranzato, M., Wolf, L., 2014. <span>DeepFace</span>: Closing the gap to human-level performance in face verification, in: Proceedings of the <span>IEEE</span> Computer Society Conference on Computer Vision and Pattern Recognition. <a href="https://doi.org/10.1109/CVPR.2014.220">https://doi.org/10.1109/CVPR.2014.220</a>
</div>
</div>
</section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@3.9.2/lib/js/head.min.js"></script>
  <script src="https://unpkg.com/reveal.js@3.9.2/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'https://unpkg.com/reveal.js@3.9.2/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'https://unpkg.com/reveal.js@3.9.2/plugin/zoom-js/zoom.js', async: true },
          { src: 'https://unpkg.com/reveal.js@3.9.2/plugin/math/math.js', async: true },
          { src: 'https://unpkg.com/reveal.js@3.9.2/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
