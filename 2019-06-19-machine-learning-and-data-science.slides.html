<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2019-06-19">
  <title>Machine Learning and Data Science</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="figure-animate.js"></script>
</head>
<body>
\[<!--\newcommand{\tk}[1]{}-->
\newcommand{\tk}[1]{\textbf{TK}: #1}
\newcommand{\Amatrix}{\mathbf{A}}
\newcommand{\KL}[2]{\text{KL}\left( #1\,\|\,#2 \right)}
\newcommand{\Kaast}{\kernelMatrix_{\mathbf{ \ast}\mathbf{ \ast}}}
\newcommand{\Kastu}{\kernelMatrix_{\mathbf{ \ast} \inducingVector}}
\newcommand{\Kff}{\kernelMatrix_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\Kfu}{\kernelMatrix_{\mappingFunctionVector \inducingVector}}
\newcommand{\Kuast}{\kernelMatrix_{\inducingVector \bf\ast}}
\newcommand{\Kuf}{\kernelMatrix_{\inducingVector \mappingFunctionVector}}
\newcommand{\Kuu}{\kernelMatrix_{\inducingVector \inducingVector}}
\newcommand{\Kuui}{\Kuu^{-1}}
\newcommand{\Qaast}{\mathbf{Q}_{\bf \ast \ast}}
\newcommand{\Qastf}{\mathbf{Q}_{\ast \mappingFunction}}
\newcommand{\Qfast}{\mathbf{Q}_{\mappingFunctionVector \bf \ast}}
\newcommand{\Qff}{\mathbf{Q}_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\aMatrix}{\mathbf{A}}
\newcommand{\aScalar}{a}
\newcommand{\aVector}{\mathbf{a}}
\newcommand{\acceleration}{a}
\newcommand{\bMatrix}{\mathbf{B}}
\newcommand{\bScalar}{b}
\newcommand{\bVector}{\mathbf{b}}
\newcommand{\basisFunc}{\phi}
\newcommand{\basisFuncVector}{\boldsymbol{ \basisFunc}}
\newcommand{\basisFunction}{\phi}
\newcommand{\basisLocation}{\mu}
\newcommand{\basisMatrix}{\boldsymbol{ \Phi}}
\newcommand{\basisScalar}{\basisFunction}
\newcommand{\basisVector}{\boldsymbol{ \basisFunction}}
\newcommand{\activationFunction}{\phi}
\newcommand{\activationMatrix}{\boldsymbol{ \Phi}}
\newcommand{\activationScalar}{\basisFunction}
\newcommand{\activationVector}{\boldsymbol{ \basisFunction}}
\newcommand{\bigO}{\mathcal{O}}
\newcommand{\binomProb}{\pi}
\newcommand{\cMatrix}{\mathbf{C}}
\newcommand{\cbasisMatrix}{\hat{\boldsymbol{ \Phi}}}
\newcommand{\cdataMatrix}{\hat{\dataMatrix}}
\newcommand{\cdataScalar}{\hat{\dataScalar}}
\newcommand{\cdataVector}{\hat{\dataVector}}
\newcommand{\centeredKernelMatrix}{\mathbf{ \MakeUppercase{\centeredKernelScalar}}}
\newcommand{\centeredKernelScalar}{b}
\newcommand{\centeredKernelVector}{\centeredKernelScalar}
\newcommand{\centeringMatrix}{\mathbf{H}}
\newcommand{\chiSquaredDist}[2]{\chi_{#1}^{2}\left(#2\right)}
\newcommand{\chiSquaredSamp}[1]{\chi_{#1}^{2}}
\newcommand{\conditionalCovariance}{\boldsymbol{ \Sigma}}
\newcommand{\coregionalizationMatrix}{\mathbf{B}}
\newcommand{\coregionalizationScalar}{b}
\newcommand{\coregionalizationVector}{\mathbf{ \coregionalizationScalar}}
\newcommand{\covDist}[2]{\text{cov}_{#2}\left(#1\right)}
\newcommand{\covSamp}[1]{\text{cov}\left(#1\right)}
\newcommand{\covarianceScalar}{c}
\newcommand{\covarianceVector}{\mathbf{ \covarianceScalar}}
\newcommand{\covarianceMatrix}{\mathbf{C}}
\newcommand{\covarianceMatrixTwo}{\boldsymbol{ \Sigma}}
\newcommand{\croupierScalar}{s}
\newcommand{\croupierVector}{\mathbf{ \croupierScalar}}
\newcommand{\croupierMatrix}{\mathbf{ \MakeUppercase{\croupierScalar}}}
\newcommand{\dataDim}{p}
\newcommand{\dataIndex}{i}
\newcommand{\dataIndexTwo}{j}
\newcommand{\dataMatrix}{\mathbf{Y}}
\newcommand{\dataScalar}{y}
\newcommand{\dataSet}{\mathcal{D}}
\newcommand{\dataStd}{\sigma}
\newcommand{\dataVector}{\mathbf{ \dataScalar}}
\newcommand{\decayRate}{d}
\newcommand{\degreeMatrix}{\mathbf{ \MakeUppercase{\degreeScalar}}}
\newcommand{\degreeScalar}{d}
\newcommand{\degreeVector}{\mathbf{ \degreeScalar}}
% Already defined by latex
%\newcommand{\det}[1]{\left|#1\right|}
\newcommand{\diag}[1]{\text{diag}\left(#1\right)}
\newcommand{\diagonalMatrix}{\mathbf{D}}
\newcommand{\diff}[2]{\frac{\text{d}#1}{\text{d}#2}}
\newcommand{\diffTwo}[2]{\frac{\text{d}^2#1}{\text{d}#2^2}}
\newcommand{\displacement}{x}
\newcommand{\displacementVector}{\textbf{\displacement}}
\newcommand{\distanceMatrix}{\mathbf{ \MakeUppercase{\distanceScalar}}}
\newcommand{\distanceScalar}{d}
\newcommand{\distanceVector}{\mathbf{ \distanceScalar}}
\newcommand{\eigenvaltwo}{\ell}
\newcommand{\eigenvaltwoMatrix}{\mathbf{L}}
\newcommand{\eigenvaltwoVector}{\mathbf{l}}
\newcommand{\eigenvalue}{\lambda}
\newcommand{\eigenvalueMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\eigenvalueVector}{\boldsymbol{ \lambda}}
\newcommand{\eigenvector}{\mathbf{ \eigenvectorScalar}}
\newcommand{\eigenvectorMatrix}{\mathbf{U}}
\newcommand{\eigenvectorScalar}{u}
\newcommand{\eigenvectwo}{\mathbf{v}}
\newcommand{\eigenvectwoMatrix}{\mathbf{V}}
\newcommand{\eigenvectwoScalar}{v}
\newcommand{\entropy}[1]{\mathcal{H}\left(#1\right)}
\newcommand{\errorFunction}{E}
\newcommand{\expDist}[2]{\left<#1\right>_{#2}}
\newcommand{\expSamp}[1]{\left<#1\right>}
\newcommand{\expectation}[1]{\left\langle #1 \right\rangle }
\newcommand{\expectationDist}[2]{\left\langle #1 \right\rangle _{#2}}
\newcommand{\expectedDistanceMatrix}{\mathcal{D}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\fantasyDim}{r}
\newcommand{\fantasyMatrix}{\mathbf{ \MakeUppercase{\fantasyScalar}}}
\newcommand{\fantasyScalar}{z}
\newcommand{\fantasyVector}{\mathbf{ \fantasyScalar}}
\newcommand{\featureStd}{\varsigma}
\newcommand{\gammaCdf}[3]{\mathcal{GAMMA CDF}\left(#1|#2,#3\right)}
\newcommand{\gammaDist}[3]{\mathcal{G}\left(#1|#2,#3\right)}
\newcommand{\gammaSamp}[2]{\mathcal{G}\left(#1,#2\right)}
\newcommand{\gaussianDist}[3]{\mathcal{N}\left(#1|#2,#3\right)}
\newcommand{\gaussianSamp}[2]{\mathcal{N}\left(#1,#2\right)}
\newcommand{\given}{|}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\heaviside}{H}
\newcommand{\hiddenMatrix}{\mathbf{ \MakeUppercase{\hiddenScalar}}}
\newcommand{\hiddenScalar}{h}
\newcommand{\hiddenVector}{\mathbf{ \hiddenScalar}}
\newcommand{\identityMatrix}{\eye}
\newcommand{\inducingInputScalar}{z}
\newcommand{\inducingInputVector}{\mathbf{ \inducingInputScalar}}
\newcommand{\inducingInputMatrix}{\mathbf{Z}}
\newcommand{\inducingScalar}{u}
\newcommand{\inducingVector}{\mathbf{ \inducingScalar}}
\newcommand{\inducingMatrix}{\mathbf{U}}
\newcommand{\inlineDiff}[2]{\text{d}#1/\text{d}#2}
\newcommand{\inputDim}{q}
\newcommand{\inputMatrix}{\mathbf{X}}
\newcommand{\inputScalar}{x}
\newcommand{\inputSpace}{\mathcal{X}}
\newcommand{\inputVals}{\inputVector}
\newcommand{\inputVector}{\mathbf{ \inputScalar}}
\newcommand{\iterNum}{k}
\newcommand{\kernel}{\kernelScalar}
\newcommand{\kernelMatrix}{\mathbf{K}}
\newcommand{\kernelScalar}{k}
\newcommand{\kernelVector}{\mathbf{ \kernelScalar}}
\newcommand{\kff}{\kernelScalar_{\mappingFunction \mappingFunction}}
\newcommand{\kfu}{\kernelVector_{\mappingFunction \inducingScalar}}
\newcommand{\kuf}{\kernelVector_{\inducingScalar \mappingFunction}}
\newcommand{\kuu}{\kernelVector_{\inducingScalar \inducingScalar}}
\newcommand{\lagrangeMultiplier}{\lambda}
\newcommand{\lagrangeMultiplierMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\lagrangian}{L}
\newcommand{\laplacianFactor}{\mathbf{ \MakeUppercase{\laplacianFactorScalar}}}
\newcommand{\laplacianFactorScalar}{m}
\newcommand{\laplacianFactorVector}{\mathbf{ \laplacianFactorScalar}}
\newcommand{\laplacianMatrix}{\mathbf{L}}
\newcommand{\laplacianScalar}{\ell}
\newcommand{\laplacianVector}{\mathbf{ \ell}}
\newcommand{\latentDim}{q}
\newcommand{\latentDistanceMatrix}{\boldsymbol{ \Delta}}
\newcommand{\latentDistanceScalar}{\delta}
\newcommand{\latentDistanceVector}{\boldsymbol{ \delta}}
\newcommand{\latentForce}{f}
\newcommand{\latentFunction}{u}
\newcommand{\latentFunctionVector}{\mathbf{ \latentFunction}}
\newcommand{\latentFunctionMatrix}{\mathbf{ \MakeUppercase{\latentFunction}}}
\newcommand{\latentIndex}{j}
\newcommand{\latentScalar}{z}
\newcommand{\latentVector}{\mathbf{ \latentScalar}}
\newcommand{\latentMatrix}{\mathbf{Z}}
\newcommand{\learnRate}{\eta}
\newcommand{\lengthScale}{\ell}
\newcommand{\rbfWidth}{\ell}
\newcommand{\likelihoodBound}{\mathcal{L}}
\newcommand{\likelihoodFunction}{L}
\newcommand{\locationScalar}{\mu}
\newcommand{\locationVector}{\boldsymbol{ \locationScalar}}
\newcommand{\locationMatrix}{\mathbf{M}}
\newcommand{\variance}[1]{\text{var}\left( #1 \right)}
\newcommand{\mappingFunction}{f}
\newcommand{\mappingFunctionMatrix}{\mathbf{F}}
\newcommand{\mappingFunctionTwo}{g}
\newcommand{\mappingFunctionTwoMatrix}{\mathbf{G}}
\newcommand{\mappingFunctionTwoVector}{\mathbf{ \mappingFunctionTwo}}
\newcommand{\mappingFunctionVector}{\mathbf{ \mappingFunction}}
\newcommand{\scaleScalar}{s}
\newcommand{\mappingScalar}{w}
\newcommand{\mappingVector}{\mathbf{ \mappingScalar}}
\newcommand{\mappingMatrix}{\mathbf{W}}
\newcommand{\mappingScalarTwo}{v}
\newcommand{\mappingVectorTwo}{\mathbf{ \mappingScalarTwo}}
\newcommand{\mappingMatrixTwo}{\mathbf{V}}
\newcommand{\maxIters}{K}
\newcommand{\meanMatrix}{\mathbf{M}}
\newcommand{\meanScalar}{\mu}
\newcommand{\meanTwoMatrix}{\mathbf{M}}
\newcommand{\meanTwoScalar}{m}
\newcommand{\meanTwoVector}{\mathbf{ \meanTwoScalar}}
\newcommand{\meanVector}{\boldsymbol{ \meanScalar}}
\newcommand{\mrnaConcentration}{m}
\newcommand{\naturalFrequency}{\omega}
\newcommand{\neighborhood}[1]{\mathcal{N}\left( #1 \right)}
\newcommand{\neilurl}{http://inverseprobability.com/}
\newcommand{\noiseMatrix}{\boldsymbol{ E}}
\newcommand{\noiseScalar}{\epsilon}
\newcommand{\noiseVector}{\boldsymbol{ \epsilon}}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\normalizedLaplacianMatrix}{\hat{\mathbf{L}}}
\newcommand{\normalizedLaplacianScalar}{\hat{\ell}}
\newcommand{\normalizedLaplacianVector}{\hat{\mathbf{ \ell}}}
\newcommand{\numActive}{m}
\newcommand{\numBasisFunc}{m}
\newcommand{\numComponents}{m}
\newcommand{\numComps}{K}
\newcommand{\numData}{n}
\newcommand{\numFeatures}{K}
\newcommand{\numHidden}{h}
\newcommand{\numInducing}{m}
\newcommand{\numLayers}{\ell}
\newcommand{\numNeighbors}{K}
\newcommand{\numSequences}{s}
\newcommand{\numSuccess}{s}
\newcommand{\numTasks}{m}
\newcommand{\numTime}{T}
\newcommand{\numTrials}{S}
\newcommand{\outputIndex}{j}
\newcommand{\paramVector}{\boldsymbol{ \theta}}
\newcommand{\parameterMatrix}{\boldsymbol{ \Theta}}
\newcommand{\parameterScalar}{\theta}
\newcommand{\parameterVector}{\boldsymbol{ \parameterScalar}}
\newcommand{\partDiff}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\precisionScalar}{j}
\newcommand{\precisionVector}{\mathbf{ \precisionScalar}}
\newcommand{\precisionMatrix}{\mathbf{J}}
\newcommand{\pseudotargetScalar}{\widetilde{y}}
\newcommand{\pseudotargetVector}{\mathbf{ \pseudotargetScalar}}
\newcommand{\pseudotargetMatrix}{\mathbf{ \widetilde{Y}}}
\newcommand{\rank}[1]{\text{rank}\left(#1\right)}
\newcommand{\rayleighDist}[2]{\mathcal{R}\left(#1|#2\right)}
\newcommand{\rayleighSamp}[1]{\mathcal{R}\left(#1\right)}
\newcommand{\responsibility}{r}
\newcommand{\rotationScalar}{r}
\newcommand{\rotationVector}{\mathbf{ \rotationScalar}}
\newcommand{\rotationMatrix}{\mathbf{R}}
\newcommand{\sampleCovScalar}{s}
\newcommand{\sampleCovVector}{\mathbf{ \sampleCovScalar}}
\newcommand{\sampleCovMatrix}{\mathbf{s}}
\newcommand{\scalarProduct}[2]{\left\langle{#1},{#2}\right\rangle}
\newcommand{\sign}[1]{\text{sign}\left(#1\right)}
\newcommand{\sigmoid}[1]{\sigma\left(#1\right)}
\newcommand{\singularvalue}{\ell}
\newcommand{\singularvalueMatrix}{\mathbf{L}}
\newcommand{\singularvalueVector}{\mathbf{l}}
\newcommand{\sorth}{\mathbf{u}}
\newcommand{\spar}{\lambda}
\newcommand{\trace}[1]{\text{tr}\left(#1\right)}
\newcommand{\BasalRate}{B}
\newcommand{\DampingCoefficient}{C}
\newcommand{\DecayRate}{D}
\newcommand{\Displacement}{X}
\newcommand{\LatentForce}{F}
\newcommand{\Mass}{M}
\newcommand{\Sensitivity}{S}
\newcommand{\basalRate}{b}
\newcommand{\dampingCoefficient}{c}
\newcommand{\mass}{m}
\newcommand{\sensitivity}{s}
\newcommand{\springScalar}{\kappa}
\newcommand{\springVector}{\boldsymbol{ \kappa}}
\newcommand{\springMatrix}{\boldsymbol{ \mathcal{K}}}
\newcommand{\tfConcentration}{p}
\newcommand{\tfDecayRate}{\delta}
\newcommand{\tfMrnaConcentration}{f}
\newcommand{\tfVector}{\mathbf{ \tfConcentration}}
\newcommand{\velocity}{v}
\newcommand{\sufficientStatsScalar}{g}
\newcommand{\sufficientStatsVector}{\mathbf{ \sufficientStatsScalar}}
\newcommand{\sufficientStatsMatrix}{\mathbf{G}}
\newcommand{\switchScalar}{s}
\newcommand{\switchVector}{\mathbf{ \switchScalar}}
\newcommand{\switchMatrix}{\mathbf{S}}
\newcommand{\tr}[1]{\text{tr}\left(#1\right)}
\newcommand{\loneNorm}[1]{\left\Vert #1 \right\Vert_1}
\newcommand{\ltwoNorm}[1]{\left\Vert #1 \right\Vert_2}
\newcommand{\onenorm}[1]{\left\vert#1\right\vert_1}
\newcommand{\twonorm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\vScalar}{v}
\newcommand{\vVector}{\mathbf{v}}
\newcommand{\vMatrix}{\mathbf{V}}
\newcommand{\varianceDist}[2]{\text{var}_{#2}\left( #1 \right)}
% Already defined by latex
%\newcommand{\vec}{#1:}
\newcommand{\vecb}[1]{\left(#1\right):}
\newcommand{\weightScalar}{w}
\newcommand{\weightVector}{\mathbf{ \weightScalar}}
\newcommand{\weightMatrix}{\mathbf{W}}
\newcommand{\weightedAdjacencyMatrix}{\mathbf{A}}
\newcommand{\weightedAdjacencyScalar}{a}
\newcommand{\weightedAdjacencyVector}{\mathbf{ \weightedAdjacencyScalar}}
\newcommand{\onesVector}{\mathbf{1}}
\newcommand{\zerosVector}{\mathbf{0}}
\]
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Machine Learning and Data Science</h1>
  <p class="subtitle" style="text-align:center">Data First Design</p>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2019-06-19</time></p>
  <p class="venue" style="text-align:center">Department of Housing, Commmunities and Local Government</p>
</section>

<section class="slide level3">

<!-- Front matter -->
<!-- Front matter -->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!--Back matter-->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
</section>
<section id="section" class="slide level3">
<h3></h3>
<p><span class="math display">\[\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}\]</span></p>
</section>
<section id="from-model-to-decision" class="slide level3">
<h3>From Model to Decision</h3>
</section>
<section id="section-1" class="slide level3">
<h3></h3>
<table>
<tr>
<td width="35%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/earth_PNG37.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="45%">
<span class="math display">\[\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}\]</span>
</td>
<td width="20%">
<object class="svgplot " data="../slides/diagrams/ai/1969018.svg" width="100%" style="center ">
</object>
</td>
</tr>
</table>
</section>
<section id="artificial-intelligence-and-data-science" class="slide level3">
<h3>Artificial Intelligence and Data Science</h3>
<ul>
<li>AI aims to equip computers with human capabilities
<ul>
<li>Image understanding</li>
<li>Computer vision</li>
<li>Speech recognition</li>
<li>Natural language understanding</li>
<li>Machine translation</li>
</ul></li>
</ul>
</section>
<section id="supervised-learning-for-ai" class="slide level3">
<h3>Supervised Learning for AI</h3>
<ul>
<li>Dominant approach today:
<ul>
<li>Generate large labelled data set from humans.</li>
<li>Use <em>supervised learning</em> to emulate that data.
<ul>
<li><em>E.g.</em> <a href="www.image-net.org">ImageNet</a> <span class="citation" data-cites="Russakovsky-imagenet15">Russakovsky et al. (2015)</span></li>
</ul></li>
</ul></li>
<li>Significant advances due to <em>deep learning</em>
<ul>
<li><em>E.g.</em> Alexa, Amazon Go</li>
</ul></li>
</ul>
</section>
<section id="data-science" class="slide level3">
<h3>Data Science</h3>
<ul>
<li>Arises from <em>happenstance data</em>.</li>
<li>Differs from statistics in that the question comes <em>after</em> data collection.</li>
</ul>
</section>
<section id="amazon-bits-and-atoms" class="slide level3">
<h3>Amazon: Bits and Atoms</h3>
<!--
include{../_ai/includes/embodiment-factors.md}
include{_data-science/includes/evolved-relationship.md}
include{_ml/includes/what-does-machine-learning-do.md}

newslide{Deep Learning}

* These are interpretable models: vital for disease etc.

* Modern machine learning methods are less interpretable

* Example: face recognition

include{_ml/includes/deep-learning-overview.md}-->
<!--include{_gp/includes/gp-intro-very-short.md}-->
<!--include{_deepgp/includes/deep-olympic.md}-->
<!--
include{_data-science/includes/a-time-for-professionalisation.md}
include{_data-science/includes/the-data-crisis.md} 

newslide{Rest of this Talk: Two Areas of Focus}

* Reusability of Data
* Deployment of Machine Learning Systems

newslide{Rest of this Talk: Two Areas of Focus}

* <s>Reusability of Data</s>
* Deployment of Machine Learning Systems

include{_data-science/includes/data-readiness-levels.md}


### Artificial Intelligence  {}



* Challenges in deploying AI.
* Currently this is in the form of "machine learning systems"


### Internet of People  {}



* Fog computing: barrier between cloud and device blurring.
    * Computing on the Edge
* Complex feedback between algorithm and implementation
  

### Deploying ML in Real World: Machine Learning Systems Design  {}



* Major new challenge for systems designers.
* Internet of Intelligence but currently:
    * AI systems are *fragile*





-->
</section>
<section id="machine-learning-in-supply-chain" class="slide level3">
<h3>Machine Learning in Supply Chain</h3>
<div class="figure">
<div id="packhorse-bridge-burbage-brook-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/packhorse-bridge-burbage-brook.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="section-2" class="slide level3">
<h3></h3>
<div class="figure">
<div id="cromford-mill-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/cromford-mill.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="section-3" class="slide level3">
<h3></h3>
<div class="figure">
<div id="container-2539942_1920-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/container-2539942_1920.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="deep-freeze" class="slide level3">
<h3>Deep Freeze</h3>
<div class="figure">
<div id="wild-alaskan-cod-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/wild-alaskan-cod.jpg" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="deep-freeze-1" class="slide level3">
<h3>Deep Freeze</h3>
<div class="figure">
<div id="wild-alaskan-cod-made-in-china-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/wild-alaskan-cod-made-in-china.jpg" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="machine-learning-in-supply-chain-1" class="slide level3">
<h3>Machine Learning in Supply Chain</h3>
<ul>
<li><em>Supply chain</em>: Large Automated Decision Making Network</li>
<li>Amazon's supply chain: Possibly the world's largest 'AI'</li>
<li>Major Challenge:
<ul>
<li>We have a <em>mechanistic</em> understanding of supply chain.</li>
<li>Machine learning is a <em>data driven</em> technology.</li>
</ul></li>
</ul>
</section>
<section id="amazon-supply-chain-optimization" class="slide level3">
<h3>Amazon Supply Chain Optimization</h3>
<div class="figure">
<div id="supply-chain-optimization-team-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/ncwsr1Of6Cw?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
</div>
</section>
<section id="the-tribal-mentality" class="slide level3">
<h3>The Tribal Mentality</h3>
<ul>
<li><span class="math inline">\(\text{data} + \text{model}\)</span> is <em>not</em> new.
<ul>
<li>Dates back to Newton, Laplace, Gauss</li>
</ul></li>
<li><em>Plethora</em> of fields: <em>E.g.</em>
<ul>
<li>Operations Research</li>
<li>Control</li>
<li>Econometrics</li>
<li>Statistics</li>
<li>Machine learning</li>
<li>Data science</li>
</ul></li>
</ul>
</section>
<section id="the-tribal-mentality-1" class="slide level3">
<h3>The Tribal Mentality</h3>
<ul>
<li>This can lead to confusion:
<ul>
<li>Different academic fields are:
<ul>
<li>Born in different eras</li>
<li>Driven by different motivations</li>
<li>Arrive at different solutions</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="tribalism-can-be-good" class="slide level3">
<h3>Tribalism Can be Good</h3>
<ul>
<li>Allows for consensus on best practice.</li>
<li>Shared set of goals</li>
<li>Ease of commiunication</li>
<li>Rapid deployment of robust solutions</li>
</ul>
</section>
<section id="professional-tribes" class="slide level3">
<h3>Professional Tribes</h3>
<ul>
<li>This is the nature of professions
<ul>
<li>lawyers</li>
<li>medics</li>
<li>doctors</li>
<li>engineers</li>
<li>accountants</li>
</ul></li>
</ul>
</section>
<section id="different-views" class="slide level3">
<h3>Different Views</h3>
<p><span class="math display">\[\text{data} + \text{model}\]</span></p>
<ul>
<li>For OR, control, stats etc.</li>
<li>More things <em>unite</em> us rather than <em>divide</em> us.</li>
</ul>
</section>
<section id="were-no-longer-hunter-gatherers-..." class="slide level3">
<h3>We're no longer hunter gatherers ...</h3>
<ul>
<li>The automation challenges we face require
<ul>
<li>all of our best ideas.</li>
<li>rethinking what <span class="math inline">\(\text{data}+\text{model}\)</span> means</li>
<li>rapid deployment and continuous monitoring</li>
</ul></li>
<li>This is the era of <em>data science</em></li>
</ul>
</section>
<section id="discomfort-and-disconformation" class="slide level3">
<h3>Discomfort and Disconformation</h3>
<ul>
<li>Talking across field boundaries is <em>critical</em>.</li>
<li>It helps us <em>disconfirm our beliefs</em>.</li>
<li>It's not comfortable, but it's vital.</li>
</ul>
</section>
<section id="the-three-ds-of-machine-learning-systems-design" class="slide level3">
<h3>The Three Ds of Machine Learning Systems Design</h3>
<ul>
<li>Three primary challenges of Machine Learning Systems Design.</li>
</ul>
<ol type="1">
<li>Decomposition</li>
<li>Data</li>
<li>Deployment</li>
</ol>
</section>
<section id="the-three-ds-of-machine-learning-systems-design-1" class="slide level3">
<h3>The Three Ds of Machine Learning Systems Design</h3>
<ul>
<li>Three primary challenges of Machine Learning Systems Design.</li>
</ul>
<ol type="1">
<li><s>Decomposition</s></li>
<li>Data</li>
<li><s>Deployment</s></li>
</ol>
</section>
<section id="data" class="slide level3">
<h3>Data</h3>
<ul>
<li>Hard to overstate its importance.</li>
<li>Half the equation of <span class="math inline">\(\text{data} + \text{model}\)</span>.</li>
<li>Often utterly neglected.</li>
</ul>
</section>
<section id="data-neglect" class="slide level3">
<h3>Data Neglect</h3>
<ul>
<li>Arises for two reasons.
<ol type="1">
<li>Data cleaning is perceived as tedious.</li>
<li>Data cleaning is complex.</li>
</ol></li>
</ul>
</section>
<section id="data-cleaning" class="slide level3">
<h3>Data Cleaning</h3>
<ul>
<li>Seems difficult to formulate into readily teachable princples.</li>
<li>Heavily neglected in data science, statistics and ML courses.</li>
<li>In practice most scientists spend around 80% of time data cleaning.</li>
</ul>
</section>
<section id="the-data-crisis" class="slide level3">
<h3>The Data Crisis</h3>
</section>
<section id="the-software-crisis" class="slide level3">
<h3>The Software Crisis</h3>
<p><small></p>
<blockquote>
<p>The major cause of the software crisis is that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming has become an equally gigantic problem.</p>
<p>Edsger Dijkstra (1930-2002), The Humble Programmer</p>
</blockquote>
<p></small></p>
</section>
<section id="the-data-crisis-1" class="slide level3">
<h3>The Data Crisis</h3>
<p><small></p>
<blockquote>
<p>The major cause of the data crisis is that machines have become more interconnected than ever before. Data access is therefore cheap, but data quality is often poor. What we need is cheap high-quality data. That implies that we develop processes for improving and verifying data quality that are efficient.</p>
<p>There would seem to be two ways for improving efficiency. Firstly, we should not duplicate work. Secondly, where possible we should automate work.</p>
<p>Me </small></p>
</blockquote>
</section>
<section id="the-data-first-paradigm" class="slide level3">
<h3>The Data First Paradigm</h3>
</section>
<section id="data-quality" class="slide level3">
<h3>Data Quality</h3>
</section>
<section id="data-readiness-levels" class="slide level3">
<h3>Data Readiness Levels</h3>
</section>
<section id="section-4" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="" src="../slides/diagrams/data-science/data-readiness-levels.png" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><a href="https://arxiv.org/pdf/1705.02245.pdf" class="uri">https://arxiv.org/pdf/1705.02245.pdf</a> <a href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data Readiness Levels</a> <span class="citation" data-cites="Lawrence:drl17">(Lawrence, 2017)</span></p>
</section>
<section id="three-grades-of-data-readiness" class="slide level3">
<h3>Three Grades of Data Readiness</h3>
<ul>
<li>Grade C - accessibility</li>
<li>Transition: data becomes electronically available</li>
<li>Grade B - validity</li>
<li>Transition: pose a question to the data.</li>
<li>Grade A - usability</li>
</ul>
</section>
<section id="move-beyond-software-engineering-to-data-engineering" class="slide level3">
<h3>Move Beyond Software Engineering to Data Engineering</h3>
</section>
<section id="data-science-as-debugging" class="slide level3">
<h3>Data Science as Debugging</h3>
<ul>
<li>Analogies: For Software Engineers <a href="http://inverseprobability.com/2017/03/14/data-science-as-debugging">describe data science as <em>debugging</em></a>.</li>
</ul>
<p>.</p>
</section>
<section id="in-data-science" class="slide level3">
<h3>80/20 in Data Science</h3>
<ul>
<li>Anecdotally for a given challenge
<ul>
<li>80% of time is spent on data wrangling.</li>
<li>20% of time spent on modelling.</li>
</ul></li>
<li>Many companies employ ML Engineers focussing on <em>models</em> not <em>data</em>.</li>
</ul>
</section>
<section id="section-5" class="slide level3">
<h3></h3>
<div class="figure">
<div id="derwent-valley-resevoir-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/data-science/water-bridge-hill-transport-arch-calm-544448-pxhere.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="section-6" class="slide level3">
<h3></h3>
<div class="figure">
<div id="lake-district-stream-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/data-science/1024px-Lake_District_picture.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="outlook-for-machine-learning" class="slide level3">
<h3>Outlook for Machine Learning</h3>
<ul>
<li>Risen to prominence to <em>scale</em> our activities.</li>
<li>To scale activities need more computer based automation.</li>
<li>Machine learning allows us to automate processes previously out of reach.</li>
</ul>
</section>
<section id="data-oriented-architectures" class="slide level3">
<h3>Data Oriented Architectures</h3>
<ul>
<li>Convert data to a <em>first-class citizen</em>.</li>
<li>View system as operations on <em>data streams</em>.</li>
<li>Expose data operations in a programmatic way.</li>
</ul>
</section>
<section id="streaming-system" class="slide level3">
<h3>Streaming System</h3>
<ul>
<li>Move from pull updates to push updates.</li>
<li>Operate on rows rather than columns.</li>
<li>Lead to stateless logic: persistence handled by system.</li>
<li>Example Apache Kafka + Apache Flink</li>
</ul>
</section>
<section id="apache-flink" class="slide level3">
<h3>Apache Flink</h3>
<ul>
<li>Streams and transformations</li>
<li>a stream is a (potentially never-ending) flow of data records</li>
<li>a transformation: streams as input, produces transformed streams as output</li>
</ul>
</section>
<section id="join" class="slide level3">
<h3>Join</h3>
<pre><code>stream.join(otherStream)
    .where(&lt;KeySelector&gt;)
    .equalTo(&lt;KeySelector&gt;)
    .window(&lt;WindowAssigner&gt;)
    .apply(&lt;JoinFunction&gt;)</code></pre>
</section>
<section id="trading-system" class="slide level3">
<h3>Trading System</h3>
<ul>
<li>High frequency share trading.</li>
<li>Stream of prices with millisecond updates.</li>
<li>Trades required on millisecond time line</li>
</ul>
</section>
<section id="real-price" class="slide level3">
<h3>Real Price</h3>
<object class="svgplot " data="../slides/diagrams/data-science/real-prices.svg" width="80%" style=" ">
</object>
</section>
<section id="future-price" class="slide level3">
<h3>Future Price</h3>
<object class="svgplot " data="../slides/diagrams/data-science/hypothetical-prices.svg" width="80%" style=" ">
</object>
</section>
<section id="hypothetical-streams" class="slide level3">
<h3>Hypothetical Streams</h3>
<ul>
<li>Real stream --- share prices
<ul>
<li>derived <em>hypothetical</em> stream --- share prices in future.</li>
</ul></li>
<li>Hypothetical constrained by
<ul>
<li>input constraints.</li>
<li>decision functional</li>
<li>computational requirements (latency)</li>
</ul></li>
</ul>
</section>
<section id="hypothetical-advantage" class="slide level3">
<h3>Hypothetical Advantage</h3>
<ul>
<li>Modelling is now required.</li>
<li>But modelling is declared in the ecosystem.</li>
<li>If it's manual, warnings can be used
<ul>
<li>calibration, fairness, dataset shift</li>
</ul></li>
<li>Opens door to auto-adaptable ML.</li>
</ul>
</section>
<section id="ride-sharing-system" class="slide level3">
<h3>Ride Sharing System</h3>
</section>
<section id="ride-sharing-service-oriented" class="slide level3">
<h3>Ride Sharing: Service Oriented</h3>
<object class="svgplot " data="../slides/diagrams/data-science/ride-share-service-soa.svg" width="80%" style=" ">
</object>
</section>
<section id="ride-sharing-data-oriented" class="slide level3">
<h3>Ride Sharing: Data Oriented</h3>
<object class="svgplot " data="../slides/diagrams/data-science/ride-share-service-doa.svg" width="80%" style=" ">
</object>
</section>
<section id="ride-sharing-hypothetical" class="slide level3">
<h3>Ride Sharing: Hypothetical</h3>
<object class="svgplot " data="../slides/diagrams/data-science/ride-share-service-doa-hypothetical.svg" width="80%" style=" ">
</object>
</section>
<section id="information-dynamics" class="slide level3">
<h3>Information Dynamics</h3>
<ul>
<li>Potential for information feedback loops.</li>
<li>Hypothetical streams are instantiated.</li>
<li>Nature hypothesis (e.g. price prediction) can effect reality.</li>
<li>Leads to information dynamics, similar to dynamics of governors.</li>
<li>See e.g. <a href="https://www.gla.ac.uk/schools/computing/research/researchsections/ida-section/closedloop/">Closed Loop Data Science</a> at Glasgow.</li>
</ul>
</section>
<section id="our-efforts" class="slide level3">
<h3>Our Efforts</h3>
<ul>
<li>Our framework due for release end of June 2019 (pending approval).</li>
</ul>
</section>
<section id="conclusion" class="slide level3">
<h3>Conclusion</h3>
<ul>
<li>Challenges in <em>design</em>, <em>data curation</em> and <em>model deployment</em> for ML.</li>
<li>Data oriented architectures and data first thinking are the solution.</li>
<li>Data oriented programming creates systems that are ready to deploy.</li>
<li>Opens the door to auto-adaptive ML and information dynamics analysis.</li>
</ul>
</section>
<section id="conclusion-1" class="slide level3">
<h3>Conclusion</h3>
<ul>
<li>Technologically <em>evolving</em> environment.</li>
<li>ML is a key component of decision-making.</li>
<li>Data is the key component of ML.</li>
<li>ML is <em>critically</em> dependent on data.</li>
<li>Challenges in <em>design</em>, <em>data curation</em> and <em>model deployment</em></li>
</ul>
</section>
<section id="thanks" class="slide level3">
<h3>Thanks!</h3>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li><p>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></p></li>
<li><p>Blog post on <a href="http://inverseprobability.com/2017/03/14/data-science-as-debugging">Data Science as Debugging</a></p></li>
</ul>
</section>
<section id="references" class="slide level3 unnumbered">
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Lawrence:drl17">
<p>Lawrence, N.D., 2017. Data readiness levels. arXiv.</p>
</div>
<div id="ref-Russakovsky-imagenet15">
<p>Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115, 211–252. <a href="https://doi.org/10.1007/s11263-015-0816-y" class="uri">https://doi.org/10.1007/s11263-015-0816-y</a></p>
</div>
</div>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
