<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2019-02-22">
  <title>Towards Machine Learning Systems Design</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
      <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          TeX: {
            extensions: ["color.js"]
          }
        });
      </script>
      <script>
  
  function setDivs(group) {
    var frame = document.getElementById("range-".concat(group)).value
    slideIndex = parseInt(frame)
    showDivs(slideIndex, group);
  }
  
  function plusDivs(n, group) {
    showDivs(slideIndex += n, group);
    document.setElementById("range-".concat(group)) = slideIndex
  }
  
  function showDivs(n,group) {
    var i;
    var x = document.getElementsByClassName(group);
    if (n > x.length) {slideIndex = 1}    
    if (n < 1) {slideIndex = x.length}
    for (i = 0; i < x.length; i++) {
       x[i].style.display = "none";  
    }
    x[slideIndex-1].style.display = "block";  
  }
      </script>
</head>
<body>
\[\newcommand{\Amatrix}{\mathbf{A}}
\newcommand{\KL}[2]{\text{KL}\left( #1\,\|\,#2 \right)}
\newcommand{\Kaast}{\kernelMatrix_{\mathbf{ \ast}\mathbf{ \ast}}}
\newcommand{\Kastu}{\kernelMatrix_{\mathbf{ \ast} \inducingVector}}
\newcommand{\Kff}{\kernelMatrix_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\Kfu}{\kernelMatrix_{\mappingFunctionVector \inducingVector}}
\newcommand{\Kuast}{\kernelMatrix_{\inducingVector \bf\ast}}
\newcommand{\Kuf}{\kernelMatrix_{\inducingVector \mappingFunctionVector}}
\newcommand{\Kuu}{\kernelMatrix_{\inducingVector \inducingVector}}
\newcommand{\Kuui}{\Kuu^{-1}}
\newcommand{\Qaast}{\mathbf{Q}_{\bf \ast \ast}}
\newcommand{\Qastf}{\mathbf{Q}_{\ast \mappingFunction}}
\newcommand{\Qfast}{\mathbf{Q}_{\mappingFunctionVector \bf \ast}}
\newcommand{\Qff}{\mathbf{Q}_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\aMatrix}{\mathbf{A}}
\newcommand{\aScalar}{a}
\newcommand{\aVector}{\mathbf{a}}
\newcommand{\acceleration}{a}
\newcommand{\bMatrix}{\mathbf{B}}
\newcommand{\bScalar}{b}
\newcommand{\bVector}{\mathbf{b}}
\newcommand{\basisFunc}{\phi}
\newcommand{\basisFuncVector}{\boldsymbol{ \basisFunc}}
\newcommand{\basisFunction}{\phi}
\newcommand{\basisLocation}{\mu}
\newcommand{\basisMatrix}{\boldsymbol{ \Phi}}
\newcommand{\basisScalar}{\basisFunction}
\newcommand{\basisVector}{\boldsymbol{ \basisFunction}}
\newcommand{\activationFunction}{\phi}
\newcommand{\activationMatrix}{\boldsymbol{ \Phi}}
\newcommand{\activationScalar}{\basisFunction}
\newcommand{\activationVector}{\boldsymbol{ \basisFunction}}
\newcommand{\bigO}{\mathcal{O}}
\newcommand{\binomProb}{\pi}
\newcommand{\cMatrix}{\mathbf{C}}
\newcommand{\cbasisMatrix}{\hat{\boldsymbol{ \Phi}}}
\newcommand{\cdataMatrix}{\hat{\dataMatrix}}
\newcommand{\cdataScalar}{\hat{\dataScalar}}
\newcommand{\cdataVector}{\hat{\dataVector}}
\newcommand{\centeredKernelMatrix}{\mathbf{ \MakeUppercase{\centeredKernelScalar}}}
\newcommand{\centeredKernelScalar}{b}
\newcommand{\centeredKernelVector}{\centeredKernelScalar}
\newcommand{\centeringMatrix}{\mathbf{H}}
\newcommand{\chiSquaredDist}[2]{\chi_{#1}^{2}\left(#2\right)}
\newcommand{\chiSquaredSamp}[1]{\chi_{#1}^{2}}
\newcommand{\conditionalCovariance}{\boldsymbol{ \Sigma}}
\newcommand{\coregionalizationMatrix}{\mathbf{B}}
\newcommand{\coregionalizationScalar}{b}
\newcommand{\coregionalizationVector}{\mathbf{ \coregionalizationScalar}}
\newcommand{\covDist}[2]{\text{cov}_{#2}\left(#1\right)}
\newcommand{\covSamp}[1]{\text{cov}\left(#1\right)}
\newcommand{\covarianceScalar}{c}
\newcommand{\covarianceVector}{\mathbf{ \covarianceScalar}}
\newcommand{\covarianceMatrix}{\mathbf{C}}
\newcommand{\covarianceMatrixTwo}{\boldsymbol{ \Sigma}}
\newcommand{\croupierScalar}{s}
\newcommand{\croupierVector}{\mathbf{ \croupierScalar}}
\newcommand{\croupierMatrix}{\mathbf{ \MakeUppercase{\croupierScalar}}}
\newcommand{\dataDim}{p}
\newcommand{\dataIndex}{i}
\newcommand{\dataIndexTwo}{j}
\newcommand{\dataMatrix}{\mathbf{Y}}
\newcommand{\dataScalar}{y}
\newcommand{\dataSet}{\mathcal{D}}
\newcommand{\dataStd}{\sigma}
\newcommand{\dataVector}{\mathbf{ \dataScalar}}
\newcommand{\decayRate}{d}
\newcommand{\degreeMatrix}{\mathbf{ \MakeUppercase{\degreeScalar}}}
\newcommand{\degreeScalar}{d}
\newcommand{\degreeVector}{\mathbf{ \degreeScalar}}
% Already defined by latex
%\newcommand{\det}[1]{\left|#1\right|}
\newcommand{\diag}[1]{\text{diag}\left(#1\right)}
\newcommand{\diagonalMatrix}{\mathbf{D}}
\newcommand{\diff}[2]{\frac{\text{d}#1}{\text{d}#2}}
\newcommand{\diffTwo}[2]{\frac{\text{d}^2#1}{\text{d}#2^2}}
\newcommand{\displacement}{x}
\newcommand{\displacementVector}{\textbf{\displacement}}
\newcommand{\distanceMatrix}{\mathbf{ \MakeUppercase{\distanceScalar}}}
\newcommand{\distanceScalar}{d}
\newcommand{\distanceVector}{\mathbf{ \distanceScalar}}
\newcommand{\eigenvaltwo}{\ell}
\newcommand{\eigenvaltwoMatrix}{\mathbf{L}}
\newcommand{\eigenvaltwoVector}{\mathbf{l}}
\newcommand{\eigenvalue}{\lambda}
\newcommand{\eigenvalueMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\eigenvalueVector}{\boldsymbol{ \lambda}}
\newcommand{\eigenvector}{\mathbf{ \eigenvectorScalar}}
\newcommand{\eigenvectorMatrix}{\mathbf{U}}
\newcommand{\eigenvectorScalar}{u}
\newcommand{\eigenvectwo}{\mathbf{v}}
\newcommand{\eigenvectwoMatrix}{\mathbf{V}}
\newcommand{\eigenvectwoScalar}{v}
\newcommand{\entropy}[1]{\mathcal{H}\left(#1\right)}
\newcommand{\errorFunction}{E}
\newcommand{\expDist}[2]{\left<#1\right>_{#2}}
\newcommand{\expSamp}[1]{\left<#1\right>}
\newcommand{\expectation}[1]{\left\langle #1 \right\rangle }
\newcommand{\expectationDist}[2]{\left\langle #1 \right\rangle _{#2}}
\newcommand{\expectedDistanceMatrix}{\mathcal{D}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\fantasyDim}{r}
\newcommand{\fantasyMatrix}{\mathbf{ \MakeUppercase{\fantasyScalar}}}
\newcommand{\fantasyScalar}{z}
\newcommand{\fantasyVector}{\mathbf{ \fantasyScalar}}
\newcommand{\featureStd}{\varsigma}
\newcommand{\gammaCdf}[3]{\mathcal{GAMMA CDF}\left(#1|#2,#3\right)}
\newcommand{\gammaDist}[3]{\mathcal{G}\left(#1|#2,#3\right)}
\newcommand{\gammaSamp}[2]{\mathcal{G}\left(#1,#2\right)}
\newcommand{\gaussianDist}[3]{\mathcal{N}\left(#1|#2,#3\right)}
\newcommand{\gaussianSamp}[2]{\mathcal{N}\left(#1,#2\right)}
\newcommand{\given}{|}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\heaviside}{H}
\newcommand{\hiddenMatrix}{\mathbf{ \MakeUppercase{\hiddenScalar}}}
\newcommand{\hiddenScalar}{h}
\newcommand{\hiddenVector}{\mathbf{ \hiddenScalar}}
\newcommand{\identityMatrix}{\eye}
\newcommand{\inducingInputScalar}{z}
\newcommand{\inducingInputVector}{\mathbf{ \inducingInputScalar}}
\newcommand{\inducingInputMatrix}{\mathbf{Z}}
\newcommand{\inducingScalar}{u}
\newcommand{\inducingVector}{\mathbf{ \inducingScalar}}
\newcommand{\inducingMatrix}{\mathbf{U}}
\newcommand{\inlineDiff}[2]{\text{d}#1/\text{d}#2}
\newcommand{\inputDim}{q}
\newcommand{\inputMatrix}{\mathbf{X}}
\newcommand{\inputScalar}{x}
\newcommand{\inputSpace}{\mathcal{X}}
\newcommand{\inputVals}{\inputVector}
\newcommand{\inputVector}{\mathbf{ \inputScalar}}
\newcommand{\iterNum}{k}
\newcommand{\kernel}{\kernelScalar}
\newcommand{\kernelMatrix}{\mathbf{K}}
\newcommand{\kernelScalar}{k}
\newcommand{\kernelVector}{\mathbf{ \kernelScalar}}
\newcommand{\kff}{\kernelScalar_{\mappingFunction \mappingFunction}}
\newcommand{\kfu}{\kernelVector_{\mappingFunction \inducingScalar}}
\newcommand{\kuf}{\kernelVector_{\inducingScalar \mappingFunction}}
\newcommand{\kuu}{\kernelVector_{\inducingScalar \inducingScalar}}
\newcommand{\lagrangeMultiplier}{\lambda}
\newcommand{\lagrangeMultiplierMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\lagrangian}{L}
\newcommand{\laplacianFactor}{\mathbf{ \MakeUppercase{\laplacianFactorScalar}}}
\newcommand{\laplacianFactorScalar}{m}
\newcommand{\laplacianFactorVector}{\mathbf{ \laplacianFactorScalar}}
\newcommand{\laplacianMatrix}{\mathbf{L}}
\newcommand{\laplacianScalar}{\ell}
\newcommand{\laplacianVector}{\mathbf{ \ell}}
\newcommand{\latentDim}{q}
\newcommand{\latentDistanceMatrix}{\boldsymbol{ \Delta}}
\newcommand{\latentDistanceScalar}{\delta}
\newcommand{\latentDistanceVector}{\boldsymbol{ \delta}}
\newcommand{\latentForce}{f}
\newcommand{\latentFunction}{u}
\newcommand{\latentFunctionVector}{\mathbf{ \latentFunction}}
\newcommand{\latentFunctionMatrix}{\mathbf{ \MakeUppercase{\latentFunction}}}
\newcommand{\latentIndex}{j}
\newcommand{\latentScalar}{z}
\newcommand{\latentVector}{\mathbf{ \latentScalar}}
\newcommand{\latentMatrix}{\mathbf{Z}}
\newcommand{\learnRate}{\eta}
\newcommand{\lengthScale}{\ell}
\newcommand{\rbfWidth}{\ell}
\newcommand{\likelihoodBound}{\mathcal{L}}
\newcommand{\likelihoodFunction}{L}
\newcommand{\locationScalar}{\mu}
\newcommand{\locationVector}{\boldsymbol{ \locationScalar}}
\newcommand{\locationMatrix}{\mathbf{M}}
\newcommand{\variance}[1]{\text{var}\left( #1 \right)}
\newcommand{\mappingFunction}{f}
\newcommand{\mappingFunctionMatrix}{\mathbf{F}}
\newcommand{\mappingFunctionTwo}{g}
\newcommand{\mappingFunctionTwoMatrix}{\mathbf{G}}
\newcommand{\mappingFunctionTwoVector}{\mathbf{ \mappingFunctionTwo}}
\newcommand{\mappingFunctionVector}{\mathbf{ \mappingFunction}}
\newcommand{\scaleScalar}{s}
\newcommand{\mappingScalar}{w}
\newcommand{\mappingVector}{\mathbf{ \mappingScalar}}
\newcommand{\mappingMatrix}{\mathbf{W}}
\newcommand{\mappingScalarTwo}{v}
\newcommand{\mappingVectorTwo}{\mathbf{ \mappingScalarTwo}}
\newcommand{\mappingMatrixTwo}{\mathbf{V}}
\newcommand{\maxIters}{K}
\newcommand{\meanMatrix}{\mathbf{M}}
\newcommand{\meanScalar}{\mu}
\newcommand{\meanTwoMatrix}{\mathbf{M}}
\newcommand{\meanTwoScalar}{m}
\newcommand{\meanTwoVector}{\mathbf{ \meanTwoScalar}}
\newcommand{\meanVector}{\boldsymbol{ \meanScalar}}
\newcommand{\mrnaConcentration}{m}
\newcommand{\naturalFrequency}{\omega}
\newcommand{\neighborhood}[1]{\mathcal{N}\left( #1 \right)}
\newcommand{\neilurl}{http://inverseprobability.com/}
\newcommand{\noiseMatrix}{\boldsymbol{ E}}
\newcommand{\noiseScalar}{\epsilon}
\newcommand{\noiseVector}{\boldsymbol{ \epsilon}}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\normalizedLaplacianMatrix}{\hat{\mathbf{L}}}
\newcommand{\normalizedLaplacianScalar}{\hat{\ell}}
\newcommand{\normalizedLaplacianVector}{\hat{\mathbf{ \ell}}}
\newcommand{\numActive}{m}
\newcommand{\numBasisFunc}{m}
\newcommand{\numComponents}{m}
\newcommand{\numComps}{K}
\newcommand{\numData}{n}
\newcommand{\numFeatures}{K}
\newcommand{\numHidden}{h}
\newcommand{\numInducing}{m}
\newcommand{\numLayers}{\ell}
\newcommand{\numNeighbors}{K}
\newcommand{\numSequences}{s}
\newcommand{\numSuccess}{s}
\newcommand{\numTasks}{m}
\newcommand{\numTime}{T}
\newcommand{\numTrials}{S}
\newcommand{\outputIndex}{j}
\newcommand{\paramVector}{\boldsymbol{ \theta}}
\newcommand{\parameterMatrix}{\boldsymbol{ \Theta}}
\newcommand{\parameterScalar}{\theta}
\newcommand{\parameterVector}{\boldsymbol{ \parameterScalar}}
\newcommand{\partDiff}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\precisionScalar}{j}
\newcommand{\precisionVector}{\mathbf{ \precisionScalar}}
\newcommand{\precisionMatrix}{\mathbf{J}}
\newcommand{\pseudotargetScalar}{\widetilde{y}}
\newcommand{\pseudotargetVector}{\mathbf{ \pseudotargetScalar}}
\newcommand{\pseudotargetMatrix}{\mathbf{ \widetilde{Y}}}
\newcommand{\rank}[1]{\text{rank}\left(#1\right)}
\newcommand{\rayleighDist}[2]{\mathcal{R}\left(#1|#2\right)}
\newcommand{\rayleighSamp}[1]{\mathcal{R}\left(#1\right)}
\newcommand{\responsibility}{r}
\newcommand{\rotationScalar}{r}
\newcommand{\rotationVector}{\mathbf{ \rotationScalar}}
\newcommand{\rotationMatrix}{\mathbf{R}}
\newcommand{\sampleCovScalar}{s}
\newcommand{\sampleCovVector}{\mathbf{ \sampleCovScalar}}
\newcommand{\sampleCovMatrix}{\mathbf{s}}
\newcommand{\scalarProduct}[2]{\left\langle{#1},{#2}\right\rangle}
\newcommand{\sign}[1]{\text{sign}\left(#1\right)}
\newcommand{\sigmoid}[1]{\sigma\left(#1\right)}
\newcommand{\singularvalue}{\ell}
\newcommand{\singularvalueMatrix}{\mathbf{L}}
\newcommand{\singularvalueVector}{\mathbf{l}}
\newcommand{\sorth}{\mathbf{u}}
\newcommand{\spar}{\lambda}
\newcommand{\trace}[1]{\text{tr}\left(#1\right)}
\newcommand{\BasalRate}{B}
\newcommand{\DampingCoefficient}{C}
\newcommand{\DecayRate}{D}
\newcommand{\Displacement}{X}
\newcommand{\LatentForce}{F}
\newcommand{\Mass}{M}
\newcommand{\Sensitivity}{S}
\newcommand{\basalRate}{b}
\newcommand{\dampingCoefficient}{c}
\newcommand{\mass}{m}
\newcommand{\sensitivity}{s}
\newcommand{\springScalar}{\kappa}
\newcommand{\springVector}{\boldsymbol{ \kappa}}
\newcommand{\springMatrix}{\boldsymbol{ \mathcal{K}}}
\newcommand{\tfConcentration}{p}
\newcommand{\tfDecayRate}{\delta}
\newcommand{\tfMrnaConcentration}{f}
\newcommand{\tfVector}{\mathbf{ \tfConcentration}}
\newcommand{\velocity}{v}
\newcommand{\sufficientStatsScalar}{g}
\newcommand{\sufficientStatsVector}{\mathbf{ \sufficientStatsScalar}}
\newcommand{\sufficientStatsMatrix}{\mathbf{G}}
\newcommand{\switchScalar}{s}
\newcommand{\switchVector}{\mathbf{ \switchScalar}}
\newcommand{\switchMatrix}{\mathbf{S}}
\newcommand{\tr}[1]{\text{tr}\left(#1\right)}
\newcommand{\loneNorm}[1]{\left\Vert #1 \right\Vert_1}
\newcommand{\ltwoNorm}[1]{\left\Vert #1 \right\Vert_2}
\newcommand{\onenorm}[1]{\left\vert#1\right\vert_1}
\newcommand{\twonorm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\vScalar}{v}
\newcommand{\vVector}{\mathbf{v}}
\newcommand{\vMatrix}{\mathbf{V}}
\newcommand{\varianceDist}[2]{\text{var}_{#2}\left( #1 \right)}
% Already defined by latex
%\newcommand{\vec}{#1:}
\newcommand{\vecb}[1]{\left(#1\right):}
\newcommand{\weightScalar}{w}
\newcommand{\weightVector}{\mathbf{ \weightScalar}}
\newcommand{\weightMatrix}{\mathbf{W}}
\newcommand{\weightedAdjacencyMatrix}{\mathbf{A}}
\newcommand{\weightedAdjacencyScalar}{a}
\newcommand{\weightedAdjacencyVector}{\mathbf{ \weightedAdjacencyScalar}}
\newcommand{\onesVector}{\mathbf{1}}
\newcommand{\zerosVector}{\mathbf{0}}
\]
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Towards Machine Learning Systems Design</h1>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2019-02-22</time></p>
  <p class="venue" style="text-align:center">Department of Computer Science, University of Glasgow</p>
</section>

<section class="slide level3">

<!-- Front matter -->
<!--Back matter-->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<p><span style="text-align:right"></span></p>
<!-- SECTION What is Machine Learning? -->
<p><span style="text-align:right"></span></p>
</section>
<section id="what-is-machine-learning" class="slide level3">
<h3>What is Machine Learning?</h3>
<div class="fragment">
<p><span class="math display">\[ \text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}\]</span></p>
</div>
<div class="fragment">
<ul>
<li><strong>data</strong> : observations, could be actively or passively acquired (meta-data).</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>model</strong> : assumptions, based on previous experience (other data! transfer learning etc), or beliefs about the regularities of the universe. Inductive bias.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>prediction</strong> : an action to be taken or a categorization or a quality score.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Royal Society Report: <a href="https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf">Machine Learning: Power and Promise of Computers that Learn by Example</a></li>
</ul>
</div>
</section>
<section id="what-is-machine-learning-1" class="slide level3">
<h3>What is Machine Learning?</h3>
<p><span class="math display">\[\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}\]</span></p>
<ul>
<li class="fragment">To combine data with a model need:</li>
<li class="fragment"><strong>a prediction function</strong> <span class="math inline">\(\mappingFunction(\cdot)\)</span> includes our beliefs about the regularities of the universe</li>
<li class="fragment"><strong>an objective function</strong> <span class="math inline">\(\errorFunction(\cdot)\)</span> defines the cost of misprediction.</li>
</ul>
<p><span style="text-align:right"></span></p>
</section>
<section id="machine-learning" class="slide level3">
<h3>Machine Learning</h3>
<ul>
<li>Driver of two different domains:
<ol type="1">
<li><em>Data Science</em>: arises from the fact that we now capture data by happenstance.</li>
<li><em>Artificial Intelligence</em>: emulation of human behaviour.</li>
</ol></li>
<li>Connection: Internet of Things</li>
</ul>
</section>
<section id="machine-learning-1" class="slide level3">
<h3>Machine Learning</h3>
<ul>
<li>Driver of two different domains:
<ol type="1">
<li><em>Data Science</em>: arises from the fact that we now capture data by happenstance.</li>
<li><em>Artificial Intelligence</em>: emulation of human behaviour.</li>
</ol></li>
<li>Connection: Internet of <del>Things</del></li>
</ul>
</section>
<section id="machine-learning-2" class="slide level3">
<h3>Machine Learning</h3>
<ul>
<li>Driver of two different domains:
<ol type="1">
<li><em>Data Science</em>: arises from the fact that we now capture data by happenstance.</li>
<li><em>Artificial Intelligence</em>: emulation of human behaviour.</li>
</ol></li>
<li>Connection: Internet of People</li>
</ul>
</section>
<section id="what-does-machine-learning-do" class="slide level3">
<h3>What does Machine Learning do?</h3>
<ul>
<li>ML Automates through Data
<ul>
<li><em>Strongly</em> related to statistics.</li>
<li>Field underpins revolution in <em>data science</em> and <em>AI</em></li>
</ul></li>
<li>With AI:
<ul>
<li><em>logic</em>, <em>robotics</em>, <em>computer vision</em>, <em>speech</em></li>
</ul></li>
<li>With Data Science:
<ul>
<li><em>databases</em>, <em>data mining</em>, <em>statistics</em>, <em>visualization</em></li>
</ul></li>
</ul>
<p><span style="text-align:right"></span></p>
<p><span style="text-align:right"></span></p>
</section>
<section id="embodiment-factors" class="slide level3">
<h3>“Embodiment Factors”</h3>
<p> See <span class="citation" data-cites="Lawrence:embodiment17">(“Living Together: Mind and Machine Intelligence” Lawrence, 2017)</span>(https://arxiv.org/abs/1705.07996)</p>
</section>
<section id="section" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Lotus_49-2.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-1" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/640px-Marcel_Renault_1903.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-2" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Caleb_McDuff_WIX_Silence_Racing_livery.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><span style="text-align:right"></span></p>
<!-- SECTION Evolved Relationship with Information -->
</section>
<section id="evolved-relationship" class="slide level3">
<h3>Evolved Relationship</h3>
<div class="new-flow-of-information" style="max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/new-flow-of-information001.svg" style="vertical-align:middle;height:50%">
</object>
</div>
</section>
<section id="evolved-relationship-1" class="slide level3">
<h3>Evolved Relationship</h3>
<div class="new-flow-of-information" style="max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/new-flow-of-information002.svg" style="vertical-align:middle;height:50%">
</object>
</div>
<p><span style="text-align:right"></span></p>
</section>
<section id="what-does-machine-learning-do-1" class="slide level3">
<h3>What does Machine Learning do?</h3>
<ul>
<li>Automation scales by codifying processes and automating them.</li>
<li>Need:
<ul>
<li>Interconnected components</li>
<li>Compatible components</li>
</ul></li>
<li>Early examples:
<ul>
<li>cf Colt 45, Ford Model T</li>
</ul></li>
</ul>
</section>
<section id="codify-through-mathematical-functions" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ \text{odds} = \frac{p(\text{bought})}{p(\text{not bought})} \]</span> <span class="math display">\[ \log \text{odds}  = \beta_0 + \beta_1 \text{age} + \beta_2 \text{latitude}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-1" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ p(\text{bought}) =  \sigmoid{\beta_0 + \beta_1 \text{age} + \beta_2 \text{latitude}}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-2" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ p(\text{bought}) =  \sigmoid{\boldsymbol{\beta}^\top \inputVector}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-3" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ \dataScalar =  \mappingFunction\left(\inputVector, \boldsymbol{\beta}\right).\]</span></p>
<div class="fragment">
<p>We call <span class="math inline">\(\mappingFunction(\cdot)\)</span> the <em>prediction function</em>.</p>
</div>
</section>
<section id="fit-to-data" class="slide level3">
<h3>Fit to Data</h3>
<ul>
<li>Use an objective function</li>
</ul>
<p><span class="math display">\[\errorFunction(\boldsymbol{\beta}, \dataMatrix, \inputMatrix)\]</span></p>
<div class="fragment">
<ul>
<li>E.g. least squares <span class="math display">\[\errorFunction(\boldsymbol{\beta}, \dataMatrix, \inputMatrix) = \sum_{i=1}^\numData \left(\dataScalar_i - \mappingFunction(\inputVector_i, \boldsymbol{\beta})\right)^2.\]</span></li>
</ul>
</div>
</section>
<section id="two-components" class="slide level3">
<h3>Two Components</h3>
<ul>
<li>Prediction function, <span class="math inline">\(\mappingFunction(\cdot)\)</span></li>
<li>Objective function, <span class="math inline">\(\errorFunction(\cdot)\)</span></li>
</ul>
</section>
<section id="deep-learning" class="slide level3">
<h3>Deep Learning</h3>
<ul>
<li><p>These are interpretable models: vital for disease etc.</p></li>
<li><p>Modern machine learning methods are less interpretable</p></li>
<li><p>Example: face recognition</p></li>
</ul>
<p><span style="text-align:right"></span></p>
<!-- No slide titles in this context -->
<p><span style="text-align:right"></span></p>
</section>
<section id="section-3" class="slide level3">
<h3></h3>
<p><span class="fragment fade-in"><small>Outline of the DeepFace architecture. A front-end of a single convolution-pooling-convolution filtering on the rectified input, followed by three locally-connected layers and two fully-connected layers. Color illustrates feature maps produced at each layer. The net includes more than 120 million parameters, where more than 95% come from the local and fully connected.</small></span></p>
<div class="centered" style="">
<img class="" src="../slides/diagrams/deepface_neg.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><span style="text-align:right"><small>Source: DeepFace <span class="citation" data-cites="Taigman:deepface14">(Taigman et al., 2014)</span></small></span></p>
<p><span style="text-align:right"></span></p>
</section>
<section id="section-4" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/576px-Early_Pinball.jpg" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-5" class="slide level3">
<h3></h3>
<div style="text-align:center">
<object class="svgplot " align data="../slides/diagrams/pinball001.svg" style="vertical-align:middle;">
</object>
</div>
</section>
<section id="section-6" class="slide level3">
<h3></h3>
<div style="text-align:center">
<object class="svgplot " align data="../slides/diagrams/pinball002.svg" style="vertical-align:middle;">
</object>
</div>
<p><span style="text-align:right"></span></p>
</section>
<section id="section-7" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample001.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-8" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample002.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-9" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample003.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-10" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample004.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-11" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample005.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><span style="text-align:right"></span></p>
<p><span style="text-align:right"></span></p>
</section>
<section id="olympic-marathon-data" class="slide level3">
<h3>Olympic Marathon Data</h3>
<table>
<tr>
<td width="70%">
<ul>
<li>Gold medal times for Olympic Marathon since 1896.</li>
<li>Marathons before 1924 didn’t have a standardised distance.</li>
<li>Present results using pace per km.</li>
<li>In 1904 Marathon was badly organised leading to very slow times.</li>
</ul>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Stephen_Kiprotich.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<small>Image from Wikimedia Commons <a href="http://bit.ly/16kMKHQ" class="uri">http://bit.ly/16kMKHQ</a></small>
</td>
</tr>
</table>
</section>
<section id="olympic-marathon-data-1" class="slide level3">
<h3>Olympic Marathon Data</h3>
<div style="text-align:center">
<object class="svgplot " align data="../slides/diagrams/datasets/olympic-marathon.svg" style="vertical-align:middle;">
</object>
</div>
<p><span style="text-align:right"></span></p>
</section>
<section id="alan-turing" class="slide level3">
<h3>Alan Turing</h3>
<table>
<tr>
<td width="50%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/turing-times.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="50%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/turing-run.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</section>
<section id="probability-winning-olympics" class="slide level3">
<h3>Probability Winning Olympics?</h3>
<ul>
<li>He was a formidable Marathon runner.</li>
<li>In 1946 he ran a time 2 hours 46 minutes.
<ul>
<li>That’s a pace of 3.95 min/km.</li>
</ul></li>
<li>What is the probability he would have won an Olympics if one had been held in 1946?</li>
</ul>
<!--

### 





<table><tr><td width="40%"><img class="" src="../slides/diagrams/turing-run.jpg" width="" height="auto" align="" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></td><td width="50%"><img class="" src="../slides/diagrams/turing-times.gif" width="" height="auto" align="" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></td></tr></table>

-->
</section>
<section id="olympic-marathon-data-gp" class="slide level3">
<h3>Olympic Marathon Data GP</h3>
<object class="svgplot " align data="../slides/diagrams/gp/olympic-marathon-gp.svg" style="vertical-align:middle;">
</object>
</section>
<section id="deep-gp-fit" class="slide level3">
<h3>Deep GP Fit</h3>
<ul>
<li><p>Can a Deep Gaussian process help?</p></li>
<li><p>Deep GP is one GP feeding into another.</p></li>
</ul>
</section>
<section id="olympic-marathon-data-deep-gp" class="slide level3">
<h3>Olympic Marathon Data Deep GP</h3>
<object class="svgplot " align data="../slides/diagrams/deepgp/olympic-marathon-deep-gp.svg" style="vertical-align:middle;">
</object>
</section>
<section id="olympic-marathon-data-deep-gp-1" class="slide level3">
<h3>Olympic Marathon Data Deep GP</h3>
<object class="svgplot " align data="../slides/diagrams/deepgp/olympic-marathon-deep-gp-samples.svg" style="vertical-align:middle;">
</object>
</section>
<section id="olympic-marathon-data-latent-1" class="slide level3">
<h3>Olympic Marathon Data Latent 1</h3>
<object class="svgplot " align data="../slides/diagrams/deepgp/olympic-marathon-deep-gp-layer-0.svg" style="vertical-align:middle;">
</object>
</section>
<section id="olympic-marathon-data-latent-2" class="slide level3">
<h3>Olympic Marathon Data Latent 2</h3>
<object class="svgplot " align data="../slides/diagrams/deepgp/olympic-marathon-deep-gp-layer-1.svg" style="vertical-align:middle;">
</object>
</section>
<section id="olympic-marathon-pinball-plot" class="slide level3">
<h3>Olympic Marathon Pinball Plot</h3>
<object class="svgplot " align data="../slides/diagrams/deepgp/olympic-marathon-deep-gp-pinball.svg" style="vertical-align:middle;">
</object>
<!-- 

<span style="text-align:right">\small{<a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/a-time-for-professionalisation.md">[edit]</a>}</span>


### Data Science



* Industrial Revolution 4.0?
* *Industrial Revolution* (1760-1840) term coined by Arnold Toynbee,
in 20th century.
* Maybe: But this one is dominated by *data* not *capital*
* That presents *challenges* and *opportunities* 

compare [digital oligarchy](https://www.theguardian.com/media-network/2015/mar/05/digital-oligarchy-algorithms-personal-data) vs [how Africa can benefit from the data revolution](https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information)

* Apple vs Nokia: How you handle disruption.










### A Time for Professionalisation?




* New technologies historically led to new professions:
    * Brunel (born 1806): Civil, mechanical, naval
    * Tesla (born 1856): Electrical and power
    * William Shockley (born 1910): Electronic 
    * Watts S. Humphrey (born 1927): Software



### Why?




* Codification of best practice.
* Developing trust





### Where are we?




* Perhaps around the 1980s of programming.
    * We understand ```if```, ```for```, and procedures
    * But we don't share best practice.

* Let's *avoid* the over formalisation of software engineering.





<span style="text-align:right">\small{<a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/a-time-for-professionalisation.md">[edit]</a>}</span>
 -->
<!-- 

<span style="text-align:right">\small{<a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/the-data-crisis.md">[edit]</a>}</span> 





\subsubsection{The Software Crisis}



<small>

>The major cause of the software crisis is that the machines have
>become several orders of magnitude more powerful! To put it quite
>bluntly: as long as there were no machines, programming was no problem
>at all; when we had a few weak computers, programming became a mild
>problem, and now we have gigantic computers, programming has become an
>equally gigantic problem.
>
> Edsger Dijkstra (1930-2002), The Humble Programmer

</small>


### The Data Crisis



<small>

>The major cause of the data crisis is that machines have become more
>interconnected than ever before. Data access is therefore cheap, but
>data quality is often poor. What we need is cheap high quality
>data. That implies that we develop processes for improving and
>verifying data quality that are efficient.
>
>There would seem to be two ways for improving efficiency. Firstly, we
>should not duplicate work. Secondly, where possible we should automate
>work. 
>
> Me
</small>





 -->
<!-- ### Rest of this Talk: Two Areas of Focus  -->
<!-- * Reusability of Data -->
<!-- * Deployment of Machine Learning Systems -->
<!-- ### Rest of this Talk: Two Areas of Focus  -->
<!-- * <s>Reusability of Data</s> -->
<!-- * Deployment of Machine Learning Systems -->
<!--

<span style="text-align:right">\small{<a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-readiness-levels.md">[edit]</a>}</span>

### Data Readiness Levels



<span style="text-align:right">\small{<a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-readiness-levels-short.md">[edit]</a>}</span>


### 




<div class="centered " style=""><img class="" src="../slides/diagrams/data-science/data-readiness-levels.png" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>

<https://arxiv.org/pdf/1705.02245.pdf> [Data Readiness Levels](http://inverseprobability.com/2017/01/12/data-readiness-levels) [@Lawrence:drl17]





### Three Grades of Data Readiness





* Grade C - accessibility

* Grade B - validity

* Grade A - usability




### Accessibility: Grade C



* *Hearsay* data.
* Availability, is it actually being recorded?
* privacy or legal constraints on the accessibility of the recorded data, have ethical constraints been alleviated?
* Format: log books, PDF ...
* limitations on access due to topology (e.g. it's distributed across a number of devices)
* At the end of Grade C data is ready to be loaded into analysis software (R, SPSS, Matlab, Python, Mathematica)

### Validity: Grade B



* faithfulness and representation
* visualisations.
* exploratory data analysis
* noise characterisation.


### Grade B Checks



* Missing values.
* Schema alignment, record linkage, data fusion
* Example:
    * Was a column or columns accidentally perturbed (e.g. through a sort operation that missed one or more columns)? Or was a [gene name accidentally converted to a date](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-5-80)?






### Grade B Transition



* At the end of Grade B, ready to define a *task*, or *question*
* Compare with classical statistics:
    * *Classically*: question is first data comes later.
    * *Today*: data is first question comes later.



### Data First



In a *data first* company teams own their data quality issues at least as far as grade B1.


### Usability: Grade A

* The *usability* of data
    * Grade A is about data in context.
* Consider appropriateness of a given data set to answer a particular question or to be subject to a particular analysis.





### Recursive Effects

* Grade A may also require:
    * data integration
    * active collection of new data.
    * rebalancing of data to ensure fairness
    * annotation of data by human experts 
    * revisiting the collection (and running through the appropriate stages again)



### A1 Data



* A1 data is ready to make available for *challenges* or *AutoML* platforms.



### Contribute!




<center><http://data-readiness.org></center>




### Also ...



* Encourage greater interaction between application domains and data scientists
* Encourage *visualization* of data





-->
</section>
<section id="artificial-intelligence" class="slide level3">
<h3>Artificial Intelligence</h3>
<ul>
<li><p>Challenges in deploying AI.</p></li>
<li><p>Currently this is in the form of “machine learning systems”</p></li>
</ul>
</section>
<section id="internet-of-people" class="slide level3">
<h3>Internet of People</h3>
<ul>
<li>Fog computing: barrier between cloud and device blurring.
<ul>
<li>Computing on the Edge</li>
</ul></li>
<li>Complex feedback between algorithm and implementation</li>
</ul>
</section>
<section id="deploying-ml-in-real-world-machine-learning-systems-design" class="slide level3">
<h3>Deploying ML in Real World: Machine Learning Systems Design</h3>
<ul>
<li><p>Major new challenge for systems designers.</p></li>
<li>Internet of Intelligence but currently:
<ul>
<li>AI systems are <em>fragile</em></li>
</ul></li>
</ul>
<p><span style="text-align:right"></span></p>
<!-- SECTION Machine Learning System Design -->
</section>
<section id="fragility-of-ai-systems" class="slide level3">
<h3>Fragility of AI Systems</h3>
<ul>
<li class="fragment">They are componentwise built from ML capabilities.</li>
<li class="fragment">Each capability is independently constructed and verified.</li>
<li class="fragment">Pedestrian detection</li>
<li class="fragment">Road line detection</li>
<li class="fragment">Componentwise deconstruciton is Important for verification purposes.</li>
</ul>
</section>
<section id="pigeonholing" class="slide level3">
<h3>Pigeonholing</h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/TooManyPigeons.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="robust" class="slide level3">
<h3>Robust</h3>
<ul>
<li>Need to move beyond pigeonholing tasks.</li>
<li>Need new approaches to both the design of the individual components, and the combination of components within our AI systems.</li>
</ul>
</section>
<section id="rapid-reimplementation" class="slide level3">
<h3>Rapid Reimplementation</h3>
<ul>
<li>Whole systems are being deployed.</li>
<li>But they change their environment.</li>
<li>The experience evolved adversarial behaviour.</li>
</ul>
</section>
<section id="machine-learning-systems-design" class="slide level3">
<h3>Machine Learning Systems Design</h3>
<p><span style="text-align:right"></span></p>
</section>
<section id="section-12" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/science-holborn-viaduct.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-13" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/SteamEngine_Boulton&Watt_1784.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-14" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/Centrifugal_governor.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="adversaries" class="slide level3">
<h3>Adversaries</h3>
<ul>
<li>Stuxnet</li>
<li>Mischevious-Adversarial</li>
</ul>
<p>{One of the first automated decision making systems was Watt’s governor, as held by “Science” on Holborns viaduct. Watt’s governor was a key component in his steam engine. It senses increases in speed in the engine and closed the steam valve to prevent the engine overspeeding and destroying itself. Until the invention of this device, it was a human job to do this.</p>
<p>The formal study of governors and other feedback control devices was then began by <a href="https://en.wikipedia.org/wiki/James_Clerk_Maxwell">James Clerk Maxwell</a>, the Scottish physicist. This field became the foundation of our modern techniques of artificial intelligence through Norbert Wiener’s book <em>Cybernetics</em> <span class="citation" data-cites="Wiener:cybernetics48">(Wiener, 1948)</span>. Cybernetics is Greek for governor, a word that in itself simply means helmsman in English.</p>
<p>The recent WannaCry virus that had a wide impact on our health services ecosystem was exploiting a security flaw in Windows systems that was first exploited by a virus called Stuxnet.</p>
<p>Stuxnet was a virus designed to infect the Iranian nuclear program’s Uranium enrichment centrifuges. A centrifuge is prevented from overspeed by a controller, just like Watt’s governor. Only now it is implemented in control logic, in this case on a Siemens PLC controller.</p>
<p>Stuxnet infected these controllers and took over the response signal in the centrifuge, fooling the system into thinking that no overspeed was occuring. As a result, the centrifuges destroyed themselves through spinning too fast.</p>
<p>This is equivalent to detaching Watt’s governor from the steam engine. Such sabotage would be easily recognized by a steam engine operator. The challenge for the operators of the Iranian Uranium centrifuges was that the sabotage was occurring inside the electronics.</p>
<p>That is the effect of an adversary on an intelligent system, but even without adveraries, the mischief of a 10 year old can confuse our AIs.</p>
<iframe width height src="https://www.youtube.com/embed/1y2UKz47gew?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
<p>Asking Siri “What is a trillion to the power of a thousand minus one?” leads to a 30 minute response consisting of only 9s. I found this out because my nine year old grabbed my phone and did it. The only way to stop Siri was to force closure. This is an interesting example of a system feature that’s <em>not</em> a bug, in fact it requires clever processing from Wolfram Alpha. But it’s an unexpected result from the system performing correctly.</p>
<p>This challenge of facing a circumstance that was unenvisaged in design but has consequences in deployment becomes far larger when the environment is uncontrolled. Or in the extreme case, where actions of the intelligent system effect the wider environment and change it.</p>
<p>These unforseen circumstances are likely to lead to need for much more efficient turn-around and update for our intelligent systems. Whether we are correcting for security flaws (which <em>are</em> bugs) or unenvisaged circumstantial challenges: an issue I’m referring to as <em>peppercorns</em>. Rapid deployment of system updates is required. For example, Apple have “fixed” the problem of Siri returning long numbers.</p>
<p>The challenge is particularly acute because of the <em>scale</em> at which we can deploy AI solutions. This means when something does go wrong, it may be going wrong in billions of households simultaneously.</p>
</section>
<section id="turnaround-and-update" class="slide level3">
<h3>Turnaround And Update</h3>
<ul>
<li>There is a massive need for turn around and update</li>
<li>A redeploy of the entire system.
<ul>
<li>This involves changing the way we design and deploy.</li>
</ul></li>
<li>Interface between security engineering and machine learning.</li>
</ul>
</section>
<section id="peppercorns" class="slide level3">
<h3>Peppercorns</h3>
<ul>
<li>A new name for system failures which aren’t bugs.</li>
<li>Difference between finding a fly in your soup vs a peppercorn in your soup.</li>
</ul>
<p><span style="text-align:right"></span></p>
</section>
<section id="emukit" class="slide level3">
<h3>Emukit</h3>
<ul>
<li>Work by Javier Gonzalez, Andrei Paleyes, Mark Pullin, Maren Mahsereci, Alex Gessner, Aaron Klein.</li>
<li>Available on <a href="https://github.com/amzn/emukit">Github</a></li>
<li>Example <a href="https://github.com/amzn/emukit/blob/develop/notebooks/Emukit-sensitivity-montecarlo.ipynb">sensitivity notebook</a>.</li>
</ul>
</section>
<section id="emukit-software" class="slide level3">
<h3>Emukit Software</h3>
<ul>
<li><em>Multi-fidelity emulation</em>: build surrogate models for multiple sources of information;</li>
<li><em>Bayesian optimisation</em>: optimise physical experiments and tune parameters ML algorithms;</li>
<li><em>Experimental design/Active learning</em>: design experiments and perform active learning with ML models;</li>
<li><em>Sensitivity analysis</em>: analyse the influence of inputs on the outputs</li>
<li><em>Bayesian quadrature</em>: compute integrals of functions that are expensive to evaluate.</li>
</ul>
<!--include{_uq/includes/uncertainty-quantification.md}-->
</section>
<section id="conclusion" class="slide level3">
<h3>Conclusion</h3>
<ul>
<li><p>Artificial Intelligence and Data Science are fundamentally different.</p></li>
<li><p>In one you are dealing with data collected by happenstance.</p></li>
<li><p>In the other you are trying to build systems in the real world, often by actively collecting data.</p></li>
<li><p>Our approaches to systems design are building powerful machines that will be deployed in evolving environments.</p></li>
</ul>
</section>
<section id="thanks" class="slide level3">
<h3>Thanks!</h3>
<ul>
<li><p>twitter: @lawrennd</p></li>
<li><p>Blog post on <a href="http://inverseprobability.com/2017/07/17/what-is-machine-learning">What is Machine Learning?</a></p></li>
<li><p>Blog post on <a href="http://inverseprobability.com/2015/12/04/what-kind-of-ai">System Zero</a></p></li>
<li><p>Blog post on <a href="http://inverseprobability.com/2017/11/15/decision-making">Decision Making and Diversity</a></p></li>
<li><p><a href="https://medium.com/@mijordan3/artificial-intelligence-the-revolution-hasnt-happened-yet-5e1d5812e1e7">Mike Jordan’s Medium Post</a></p></li>
</ul>
</section>
<section id="references" class="slide level3 unnumbered">
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Lawrence:embodiment17">
<p>Lawrence, N.D., 2017. Living together: Mind and machine intelligence. arXiv.</p>
</div>
<div id="ref-Taigman:deepface14">
<p>Taigman, Y., Yang, M., Ranzato, M., Wolf, L., 2014. DeepFace: Closing the gap to human-level performance in face verification, in: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. <a href="https://doi.org/10.1109/CVPR.2014.220" class="uri">https://doi.org/10.1109/CVPR.2014.220</a></p>
</div>
<div id="ref-Wiener:cybernetics48">
<p>Wiener, N., 1948. Cybernetics: Control and communication in the animal and the machine. MIT Press, Cambridge, MA.</p>
</div>
</div>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
