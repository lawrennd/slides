<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2020-12-16">
  <title>AutoAI: Systems, Machine Learning and Mathematics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="../assets/css/talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="../assets/js/figure-animate.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">AutoAI: Systems, Machine Learning and Mathematics</h1>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2020-12-16</time></p>
  <p class="venue" style="text-align:center">Isaac Newton Institute Virtual Dinner</p>
</section>

<section class="slide level2">

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<!-- SECTION The Great AI Fallacy -->
</section>
<section id="the-great-ai-fallacy" class="slide level2">
<h2>The Great AI Fallacy</h2>
<div class="figure">
<div id="jeeves-springtime-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/Jeeves_in_the_Springtime_01.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
We seem to have fallen for a perspective on AI that suggests it will adapt to our schedule, rather in the manner of a 1930s manservant.
</aside>
<aside class="notes">
Since the machine learning field was rebranded as AI, done public understanding, but also more interconnection with other fields. Struggled to find a consistent definition for AI. But the definitions I think public uses have one thing in common. The idea that AI will be the first generation of automation to adapt to us.
</aside>
<!-- SECTION Intellectual Debt -->
</section>
<section id="intellectual-debt" class="slide level2">
<h2>Intellectual Debt</h2>
<div class="figure">
<div id="intellectual-debt-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ai/2020-02-12-intellectual-debt.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Jonathan Zittrain’s term to describe the challenges of explanation that come with AI is Intellectual Debt.
</aside>
</section>
<section id="technical-debt" class="slide level2">
<h2>Technical Debt</h2>
<ul>
<li>Compare with <em>technical debt</em>.</li>
<li>Highlighted by <span class="citation" data-cites="Sculley:debt15">Sculley et al. (2015)</span>.</li>
</ul>
</section>
<section id="separation-of-concerns" class="slide level2">
<h2>Separation of Concerns</h2>
</section>
<section id="intellectual-debt-1" class="slide level2">
<h2>Intellectual Debt</h2>
<ul>
<li><p>Technical debt is the inability to <em>maintain</em> your complex software system.</p></li>
<li><p>Intellectual debt is the inability to <em>explain</em> your software system.</p></li>
</ul>
</section>
<section id="fit-models-to-fit-systems" class="slide level2">
<h2>FIT Models to FIT Systems</h2>
<ul>
<li>Focus in machine learning has been on FAcT learning.</li>
<li>Fairness, accountability and Transparency in individual models.</li>
<li>But individual models aren’t the problem.</li>
<li>Fariness, interpetability and transparency required for whole system.</li>
</ul>
</section>
<section id="safeboda" class="slide level2">
<h2>SafeBoda</h2>
<div class="figure">
<div id="safe-boda-system-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ai/safe-boda.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
SafeBoda is a ride allocation system for Boda Boda drivers. Let’s imagine the capabilities we need for such an AI system.
</aside>
</section>
<section id="safeboda-1" class="slide level2">
<h2>SafeBoda</h2>
<blockquote>
<p>With road accidents set to match HIV/AIDS as the highest cause of death in low/middle income countries by 2030, SafeBoda’s aim is to modernise informal transportation and ensure safe access to mobility.</p>
</blockquote>
</section>
<section id="buying-system" class="slide level2">
<h2>Buying System</h2>
<div class="figure">
<div id="buying-system-components-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/software/buying-schematic.svg" width="40%" style=" ">
</object>
</div>
</div>
<aside class="notes">
The components of a putative automated buying system
</aside>
</section>
<section id="monolithic-system" class="slide level2">
<h2>Monolithic System</h2>
<div class="figure">
<div id="ml-system-monolith-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-monolith-purchasing.svg" width="60%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
</section>
<section id="service-oriented-architecture" class="slide level2">
<h2>Service Oriented Architecture</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="60%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
</section>
<section id="buying" class="slide level2">
<h2>Buying …</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="60%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system for making a purchase in an automated buying system.
</aside>
</section>
<section id="to-banking" class="slide level2">
<h2>… to Banking</h2>
<div class="figure">
<div id="ml-system-downstream-banking-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-banking000.svg" width="60%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system where a decision about a loan is being made on the basis of (potentially personal) data from a customer.
</aside>
</section>
<section id="statistical-emulation" class="slide level2">
<h2>Statistical Emulation</h2>
<div class="figure">
<div id="met-office-unified-model-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/simulation/unified_model_systems_13022018_1920.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
The UK Met office runs a shared code base for its simulations of climate and the weather. This plot shows the different spatial and temporal scales used.
</aside>
</section>
<section id="section" class="slide level2">
<h2></h2>
<div class="figure">
<div id="statistical-emulation-1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation000.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Real world systems consist of simulators that capture our domain knowledge about how our systems operate. Different simulators run at different speeds and granularities.
</aside>
</section>
<section id="emulation" class="slide level2">
<h2>Emulation</h2>
<div class="figure">
<div id="statistical-emulation-2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation001.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A statistical emulator is a system that reconstructs the simulation with a statistical model.
</aside>
</section>
<section id="emulation-1" class="slide level2">
<h2>Emulation</h2>
<div class="figure">
<div id="statistical-emulation-3-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation002.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A statistical emulator is a system that reconstructs the simulation with a statistical model.
</aside>
</section>
<section id="emulation-2" class="slide level2">
<h2>Emulation</h2>
<div class="figure">
<div id="statistical-emulation-4-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation003.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.
</aside>
</section>
<section id="emulation-3" class="slide level2">
<h2>Emulation</h2>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.
</aside>
</section>
<section id="emulation-4" class="slide level2">
<h2>Emulation</h2>
<div class="figure">
<div id="statistical-emulation-6-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation005.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
In modern machine learning system design, the emulator may also consider the output of ML models (for monitoring bias or accuracy) and Operations Research models..
</aside>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample001.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<aside class="notes">
Here we’re showing 20 samples taken from the prior over functions defined by our covarariance
</aside>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample002.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<aside class="notes">
We can sample many such functions, in this slide there are now 1000 in total. This is a sample from our prior over functions.
</aside>
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample003.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<aside class="notes">
Now we observe data. Here there are three data points. Conceptually in Bayesian inference we discard all samples that are distant from the data.
</aside>
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample004.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<aside class="notes">
Throwing away such samples we are left with our posterior. This is the collection of samples from the prior that are consistent with the data.
</aside>
</section>
<section id="section-5" class="slide level2">
<h2></h2>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/gp/gp_rejection_sample005.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<aside class="notes">
The elegance of the Gaussian process is that this result can be computed analytically using linear algebra.
</aside>
</section>
<section id="section-6" class="slide level2">
<h2></h2>
<div class="figure">
<div id="neil-newton-institute-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/people/1997-08-02-neil-newton-institute.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
The author standing outside the Newton Institute on 2nd August 1997, just after arriving for “Generalisation in Neural Networks and Machine Learning”, <a href="http://www.newton.ac.uk/files/reports/annual/ini_annual_report_97-98.pdf">see page 28 of this report</a>.
</aside>
</section>
<section id="deep-emulation" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
<!-- This structural learning allows us to associate data with the relevant -->
<!-- layer of the model, rather than merely on the leaf nodes of the output -->
<!-- model. When deploying the deep Gaussian process as an emulator, this -->
<!-- allows for the possibility of learning the structure of the different -->
<!-- component parts of the underlying system. This should aid the user in -->
<!-- determining the ideal system decomposition. -->
</section>
<section id="deep-emulation-1" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing001.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
</section>
<section id="deep-emulation-2" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing002.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
</section>
<section id="deep-emulation-3" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing3-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing003.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
</section>
<section id="mathematically" class="slide level2">
<h2>Mathematically</h2>
<ul>
<li><p>Composite <em>multivariate</em> function</p>
<p><span class="math display">\[
\mathbf{g}(\mathbf{ x})=\mathbf{ f}_5(\mathbf{ f}_4(\mathbf{ f}_3(\mathbf{ f}_2(\mathbf{ f}_1(\mathbf{ x}))))).
\]</span></p></li>
</ul>
</section>
<section id="equivalent-to-markov-chain" class="slide level2">
<h2>Equivalent to Markov Chain</h2>
<ul>
<li>Composite <em>multivariate</em> function <span class="math display">\[
p(\mathbf{ y}|\mathbf{ x})= p(\mathbf{ y}|\mathbf{ f}_5)p(\mathbf{ f}_5|\mathbf{ f}_4)p(\mathbf{ f}_4|\mathbf{ f}_3)p(\mathbf{ f}_3|\mathbf{ f}_2)p(\mathbf{ f}_2|\mathbf{ f}_1)p(\mathbf{ f}_1|\mathbf{ x})
\]</span></li>
</ul>
<div class="figure">
<div id="deep-markov-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/deep-markov.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Probabilistically the deep Gaussian process can be represented as a Markov chain. Indeed they can even be analyzed in this way <span class="citation" data-cites="Dunlop:deep2017">(Dunlop et al., n.d.)</span>.
</aside>
</section>
<section id="section-7" class="slide level2">
<h2></h2>
<div class="figure">
<div id="deep-markov-vertical-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/deep-markov-vertical.svg" width="7%" style=" ">
</object>
</div>
</div>
<aside class="notes">
More usually deep probabilistic models are written vertically rather than horizontally as in the Markov chain.
</aside>
</section>
<section id="why-composition" class="slide level2">
<h2>Why Composition?</h2>
<ul>
<li><p>Gaussian processes give priors over functions.</p></li>
<li><p>Elegant properties:</p>
<ul>
<li>e.g. <em>Derivatives</em> of process are also Gaussian distributed (if they exist).</li>
</ul></li>
<li><p>For particular covariance functions they are ‘universal approximators’, i.e. all functions can have support under the prior.</p></li>
<li><p>Gaussian derivatives might ring alarm bells.</p></li>
<li><p>E.g. a priori they don’t believe in function ‘jumps’.</p></li>
</ul>
</section>
<section id="stochastic-process-composition" class="slide level2">
<h2>Stochastic Process Composition</h2>
<ul>
<li><p>From a process perspective: <em>process composition</em>.</p></li>
<li><p>A (new?) way of constructing more complex <em>processes</em> based on simpler components.</p></li>
</ul>
</section>
<section id="section-8" class="slide level2">
<h2></h2>
<object class="svgplot " data="../slides/diagrams/deepgp/deep-markov-vertical.svg" width style=" ">
</object>
</section>
<section id="section-9" class="slide level2">
<h2></h2>
<div class="figure">
<div id="deep-markov-vertical-side-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/deep-markov-vertical-side.svg" width="15%" style=" ">
</object>
</div>
</div>
<aside class="notes">
More generally we aren’t constrained by the Markov chain. We can design structures that respect our belief about the underlying conditional dependencies. Here we are adding a side note from the chain.
</aside>
</section>
<section id="step-function-data" class="slide level2">
<h2>Step Function Data</h2>
<div class="figure">
<div id="step-function-data-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/datasets/step-function.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Simulation study of step function data artificially generated. Here there is a small overlap between the two lines.
</aside>
</section>
<section id="gpy-a-gaussian-process-framework-in-python" class="slide level2">
<h2>GPy: A Gaussian Process Framework in Python</h2>
<div class="figure">
<div id="gpy-software-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gpy.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
GPy is a BSD licensed software code base for implementing Gaussian process models in Python. It is designed for teaching and modelling. We welcome contributions which can be made through the Github repository <a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a>
</aside>
<center>
<a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a>
</center>
</section>
<section id="gpy-a-gaussian-process-framework-in-python-1" class="slide level2">
<h2>GPy: A Gaussian Process Framework in Python</h2>
<ul>
<li>BSD Licensed software base.</li>
<li>Wide availability of libraries, ‘modern’ scripting language.</li>
<li>Allows us to set projects to undergraduates in Comp Sci that use GPs.</li>
<li>Available through GitHub <a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a></li>
<li>Reproducible Research with Jupyter Notebook.</li>
</ul>
</section>
<section id="features" class="slide level2">
<h2>Features</h2>
<ul>
<li>Probabilistic-style programming (specify the model, not the algorithm).</li>
<li>Non-Gaussian likelihoods.</li>
<li>Multivariate outputs.</li>
<li>Dimensionality reduction.</li>
<li>Approximations for large data sets.</li>
</ul>
</section>
<section id="step-function-data-gp" class="slide level2">
<h2>Step Function Data GP</h2>
<div class="figure">
<div id="step-function-gp-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/step-function-gp.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Gaussian process fit to the step function data. Note the large error bars and the over-smoothing of the discontinuity. Error bars are shown at two standard deviations.
</aside>
</section>
<section id="step-function-data-deep-gp" class="slide level2">
<h2>Step Function Data Deep GP</h2>
<div class="figure">
<div id="step-function-deep-gp-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Deep Gaussian process fit to the step function data.
</aside>
</section>
<section id="step-function-data-deep-gp-1" class="slide level2">
<h2>Step Function Data Deep GP</h2>
<div class="figure">
<div id="step-function-deep-gp-samples-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp-samples.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Samples from the deep Gaussian process model for the step function fit.
</aside>
</section>
<section id="step-function-data-latent-1" class="slide level2">
<h2>Step Function Data Latent 1</h2>
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp-layer-0.svg" width style=" ">
</object>
</section>
<section id="step-function-data-latent-2" class="slide level2">
<h2>Step Function Data Latent 2</h2>
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp-layer-1.svg" width style=" ">
</object>
</section>
<section id="step-function-data-latent-3" class="slide level2">
<h2>Step Function Data Latent 3</h2>
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp-layer-2.svg" width style=" ">
</object>
</section>
<section id="step-function-data-latent-4" class="slide level2">
<h2>Step Function Data Latent 4</h2>
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp-layer-3.svg" width style=" ">
</object>
</section>
<section id="step-function-pinball-plot" class="slide level2">
<h2>Step Function Pinball Plot</h2>
<div class="figure">
<div id="step-function-deep-gp-pinball-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/step-function-deep-gp-pinball.svg" width="60%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Pinball plot of the deep GP fitted to the step function data. Each layer of the model pushes the ‘ball’ towards the left or right, saturating at 1 and 0. This causes the final density to be be peaked at 0 and 1. Transitions occur driven by the uncertainty of the mapping in each layer.
</aside>
</section>
<section id="thanks" class="slide level2 scrollable">
<h2 class="scrollable">Thanks!</h2>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
</section>
<section id="references" class="slide level2 unnumbered scrollable">
<h2 class="unnumbered scrollable">References</h2>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Dunlop:deep2017">
<p>Dunlop, M.M., Girolami, M.A., Stuart, A.M., Teckentrup, A.L., n.d. How deep are deep Gaussian processes? Journal of Machine Learning Research 19, 1–46.</p>
</div>
<div id="ref-Sculley:debt15">
<p>Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., Chaudhary, V., Young, M., Crespo, J.-F., Dennison, D., 2015. Hidden technical debt in machine learning systems, in: Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R. (Eds.), Advances in Neural Information Processing Systems 28. Curran Associates, Inc., pp. 2503–2511.</p>
</div>
</div>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/math/math.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
