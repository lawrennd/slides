<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2019-02-19">
  <title>Data Science and Digital Systems</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
      <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          TeX: {
            extensions: ["color.js"]
          }
        });
      </script>
      <script>
  
  function setDivs(group) {
    var frame = document.getElementById("range-".concat(group)).value
    slideIndex = parseInt(frame)
    showDivs(slideIndex, group);
  }
  
  function plusDivs(n, group) {
    showDivs(slideIndex += n, group);
    document.setElementById("range-".concat(group)) = slideIndex
  }
  
  function showDivs(n,group) {
    var i;
    var x = document.getElementsByClassName(group);
    if (n > x.length) {slideIndex = 1}    
    if (n < 1) {slideIndex = x.length}
    for (i = 0; i < x.length; i++) {
       x[i].style.display = "none";  
    }
    x[slideIndex-1].style.display = "block";  
  }
      </script>
</head>
<body>
\[\newcommand{\Amatrix}{\mathbf{A}}
\newcommand{\KL}[2]{\text{KL}\left( #1\,\|\,#2 \right)}
\newcommand{\Kaast}{\kernelMatrix_{\mathbf{ \ast}\mathbf{ \ast}}}
\newcommand{\Kastu}{\kernelMatrix_{\mathbf{ \ast} \inducingVector}}
\newcommand{\Kff}{\kernelMatrix_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\Kfu}{\kernelMatrix_{\mappingFunctionVector \inducingVector}}
\newcommand{\Kuast}{\kernelMatrix_{\inducingVector \bf\ast}}
\newcommand{\Kuf}{\kernelMatrix_{\inducingVector \mappingFunctionVector}}
\newcommand{\Kuu}{\kernelMatrix_{\inducingVector \inducingVector}}
\newcommand{\Kuui}{\Kuu^{-1}}
\newcommand{\Qaast}{\mathbf{Q}_{\bf \ast \ast}}
\newcommand{\Qastf}{\mathbf{Q}_{\ast \mappingFunction}}
\newcommand{\Qfast}{\mathbf{Q}_{\mappingFunctionVector \bf \ast}}
\newcommand{\Qff}{\mathbf{Q}_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\aMatrix}{\mathbf{A}}
\newcommand{\aScalar}{a}
\newcommand{\aVector}{\mathbf{a}}
\newcommand{\acceleration}{a}
\newcommand{\bMatrix}{\mathbf{B}}
\newcommand{\bScalar}{b}
\newcommand{\bVector}{\mathbf{b}}
\newcommand{\basisFunc}{\phi}
\newcommand{\basisFuncVector}{\boldsymbol{ \basisFunc}}
\newcommand{\basisFunction}{\phi}
\newcommand{\basisLocation}{\mu}
\newcommand{\basisMatrix}{\boldsymbol{ \Phi}}
\newcommand{\basisScalar}{\basisFunction}
\newcommand{\basisVector}{\boldsymbol{ \basisFunction}}
\newcommand{\activationFunction}{\phi}
\newcommand{\activationMatrix}{\boldsymbol{ \Phi}}
\newcommand{\activationScalar}{\basisFunction}
\newcommand{\activationVector}{\boldsymbol{ \basisFunction}}
\newcommand{\bigO}{\mathcal{O}}
\newcommand{\binomProb}{\pi}
\newcommand{\cMatrix}{\mathbf{C}}
\newcommand{\cbasisMatrix}{\hat{\boldsymbol{ \Phi}}}
\newcommand{\cdataMatrix}{\hat{\dataMatrix}}
\newcommand{\cdataScalar}{\hat{\dataScalar}}
\newcommand{\cdataVector}{\hat{\dataVector}}
\newcommand{\centeredKernelMatrix}{\mathbf{ \MakeUppercase{\centeredKernelScalar}}}
\newcommand{\centeredKernelScalar}{b}
\newcommand{\centeredKernelVector}{\centeredKernelScalar}
\newcommand{\centeringMatrix}{\mathbf{H}}
\newcommand{\chiSquaredDist}[2]{\chi_{#1}^{2}\left(#2\right)}
\newcommand{\chiSquaredSamp}[1]{\chi_{#1}^{2}}
\newcommand{\conditionalCovariance}{\boldsymbol{ \Sigma}}
\newcommand{\coregionalizationMatrix}{\mathbf{B}}
\newcommand{\coregionalizationScalar}{b}
\newcommand{\coregionalizationVector}{\mathbf{ \coregionalizationScalar}}
\newcommand{\covDist}[2]{\text{cov}_{#2}\left(#1\right)}
\newcommand{\covSamp}[1]{\text{cov}\left(#1\right)}
\newcommand{\covarianceScalar}{c}
\newcommand{\covarianceVector}{\mathbf{ \covarianceScalar}}
\newcommand{\covarianceMatrix}{\mathbf{C}}
\newcommand{\covarianceMatrixTwo}{\boldsymbol{ \Sigma}}
\newcommand{\croupierScalar}{s}
\newcommand{\croupierVector}{\mathbf{ \croupierScalar}}
\newcommand{\croupierMatrix}{\mathbf{ \MakeUppercase{\croupierScalar}}}
\newcommand{\dataDim}{p}
\newcommand{\dataIndex}{i}
\newcommand{\dataIndexTwo}{j}
\newcommand{\dataMatrix}{\mathbf{Y}}
\newcommand{\dataScalar}{y}
\newcommand{\dataSet}{\mathcal{D}}
\newcommand{\dataStd}{\sigma}
\newcommand{\dataVector}{\mathbf{ \dataScalar}}
\newcommand{\decayRate}{d}
\newcommand{\degreeMatrix}{\mathbf{ \MakeUppercase{\degreeScalar}}}
\newcommand{\degreeScalar}{d}
\newcommand{\degreeVector}{\mathbf{ \degreeScalar}}
% Already defined by latex
%\newcommand{\det}[1]{\left|#1\right|}
\newcommand{\diag}[1]{\text{diag}\left(#1\right)}
\newcommand{\diagonalMatrix}{\mathbf{D}}
\newcommand{\diff}[2]{\frac{\text{d}#1}{\text{d}#2}}
\newcommand{\diffTwo}[2]{\frac{\text{d}^2#1}{\text{d}#2^2}}
\newcommand{\displacement}{x}
\newcommand{\displacementVector}{\textbf{\displacement}}
\newcommand{\distanceMatrix}{\mathbf{ \MakeUppercase{\distanceScalar}}}
\newcommand{\distanceScalar}{d}
\newcommand{\distanceVector}{\mathbf{ \distanceScalar}}
\newcommand{\eigenvaltwo}{\ell}
\newcommand{\eigenvaltwoMatrix}{\mathbf{L}}
\newcommand{\eigenvaltwoVector}{\mathbf{l}}
\newcommand{\eigenvalue}{\lambda}
\newcommand{\eigenvalueMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\eigenvalueVector}{\boldsymbol{ \lambda}}
\newcommand{\eigenvector}{\mathbf{ \eigenvectorScalar}}
\newcommand{\eigenvectorMatrix}{\mathbf{U}}
\newcommand{\eigenvectorScalar}{u}
\newcommand{\eigenvectwo}{\mathbf{v}}
\newcommand{\eigenvectwoMatrix}{\mathbf{V}}
\newcommand{\eigenvectwoScalar}{v}
\newcommand{\entropy}[1]{\mathcal{H}\left(#1\right)}
\newcommand{\errorFunction}{E}
\newcommand{\expDist}[2]{\left<#1\right>_{#2}}
\newcommand{\expSamp}[1]{\left<#1\right>}
\newcommand{\expectation}[1]{\left\langle #1 \right\rangle }
\newcommand{\expectationDist}[2]{\left\langle #1 \right\rangle _{#2}}
\newcommand{\expectedDistanceMatrix}{\mathcal{D}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\fantasyDim}{r}
\newcommand{\fantasyMatrix}{\mathbf{ \MakeUppercase{\fantasyScalar}}}
\newcommand{\fantasyScalar}{z}
\newcommand{\fantasyVector}{\mathbf{ \fantasyScalar}}
\newcommand{\featureStd}{\varsigma}
\newcommand{\gammaCdf}[3]{\mathcal{GAMMA CDF}\left(#1|#2,#3\right)}
\newcommand{\gammaDist}[3]{\mathcal{G}\left(#1|#2,#3\right)}
\newcommand{\gammaSamp}[2]{\mathcal{G}\left(#1,#2\right)}
\newcommand{\gaussianDist}[3]{\mathcal{N}\left(#1|#2,#3\right)}
\newcommand{\gaussianSamp}[2]{\mathcal{N}\left(#1,#2\right)}
\newcommand{\given}{|}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\heaviside}{H}
\newcommand{\hiddenMatrix}{\mathbf{ \MakeUppercase{\hiddenScalar}}}
\newcommand{\hiddenScalar}{h}
\newcommand{\hiddenVector}{\mathbf{ \hiddenScalar}}
\newcommand{\identityMatrix}{\eye}
\newcommand{\inducingInputScalar}{z}
\newcommand{\inducingInputVector}{\mathbf{ \inducingInputScalar}}
\newcommand{\inducingInputMatrix}{\mathbf{Z}}
\newcommand{\inducingScalar}{u}
\newcommand{\inducingVector}{\mathbf{ \inducingScalar}}
\newcommand{\inducingMatrix}{\mathbf{U}}
\newcommand{\inlineDiff}[2]{\text{d}#1/\text{d}#2}
\newcommand{\inputDim}{q}
\newcommand{\inputMatrix}{\mathbf{X}}
\newcommand{\inputScalar}{x}
\newcommand{\inputSpace}{\mathcal{X}}
\newcommand{\inputVals}{\inputVector}
\newcommand{\inputVector}{\mathbf{ \inputScalar}}
\newcommand{\iterNum}{k}
\newcommand{\kernel}{\kernelScalar}
\newcommand{\kernelMatrix}{\mathbf{K}}
\newcommand{\kernelScalar}{k}
\newcommand{\kernelVector}{\mathbf{ \kernelScalar}}
\newcommand{\kff}{\kernelScalar_{\mappingFunction \mappingFunction}}
\newcommand{\kfu}{\kernelVector_{\mappingFunction \inducingScalar}}
\newcommand{\kuf}{\kernelVector_{\inducingScalar \mappingFunction}}
\newcommand{\kuu}{\kernelVector_{\inducingScalar \inducingScalar}}
\newcommand{\lagrangeMultiplier}{\lambda}
\newcommand{\lagrangeMultiplierMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\lagrangian}{L}
\newcommand{\laplacianFactor}{\mathbf{ \MakeUppercase{\laplacianFactorScalar}}}
\newcommand{\laplacianFactorScalar}{m}
\newcommand{\laplacianFactorVector}{\mathbf{ \laplacianFactorScalar}}
\newcommand{\laplacianMatrix}{\mathbf{L}}
\newcommand{\laplacianScalar}{\ell}
\newcommand{\laplacianVector}{\mathbf{ \ell}}
\newcommand{\latentDim}{q}
\newcommand{\latentDistanceMatrix}{\boldsymbol{ \Delta}}
\newcommand{\latentDistanceScalar}{\delta}
\newcommand{\latentDistanceVector}{\boldsymbol{ \delta}}
\newcommand{\latentForce}{f}
\newcommand{\latentFunction}{u}
\newcommand{\latentFunctionVector}{\mathbf{ \latentFunction}}
\newcommand{\latentFunctionMatrix}{\mathbf{ \MakeUppercase{\latentFunction}}}
\newcommand{\latentIndex}{j}
\newcommand{\latentScalar}{z}
\newcommand{\latentVector}{\mathbf{ \latentScalar}}
\newcommand{\latentMatrix}{\mathbf{Z}}
\newcommand{\learnRate}{\eta}
\newcommand{\lengthScale}{\ell}
\newcommand{\rbfWidth}{\ell}
\newcommand{\likelihoodBound}{\mathcal{L}}
\newcommand{\likelihoodFunction}{L}
\newcommand{\locationScalar}{\mu}
\newcommand{\locationVector}{\boldsymbol{ \locationScalar}}
\newcommand{\locationMatrix}{\mathbf{M}}
\newcommand{\variance}[1]{\text{var}\left( #1 \right)}
\newcommand{\mappingFunction}{f}
\newcommand{\mappingFunctionMatrix}{\mathbf{F}}
\newcommand{\mappingFunctionTwo}{g}
\newcommand{\mappingFunctionTwoMatrix}{\mathbf{G}}
\newcommand{\mappingFunctionTwoVector}{\mathbf{ \mappingFunctionTwo}}
\newcommand{\mappingFunctionVector}{\mathbf{ \mappingFunction}}
\newcommand{\scaleScalar}{s}
\newcommand{\mappingScalar}{w}
\newcommand{\mappingVector}{\mathbf{ \mappingScalar}}
\newcommand{\mappingMatrix}{\mathbf{W}}
\newcommand{\mappingScalarTwo}{v}
\newcommand{\mappingVectorTwo}{\mathbf{ \mappingScalarTwo}}
\newcommand{\mappingMatrixTwo}{\mathbf{V}}
\newcommand{\maxIters}{K}
\newcommand{\meanMatrix}{\mathbf{M}}
\newcommand{\meanScalar}{\mu}
\newcommand{\meanTwoMatrix}{\mathbf{M}}
\newcommand{\meanTwoScalar}{m}
\newcommand{\meanTwoVector}{\mathbf{ \meanTwoScalar}}
\newcommand{\meanVector}{\boldsymbol{ \meanScalar}}
\newcommand{\mrnaConcentration}{m}
\newcommand{\naturalFrequency}{\omega}
\newcommand{\neighborhood}[1]{\mathcal{N}\left( #1 \right)}
\newcommand{\neilurl}{http://inverseprobability.com/}
\newcommand{\noiseMatrix}{\boldsymbol{ E}}
\newcommand{\noiseScalar}{\epsilon}
\newcommand{\noiseVector}{\boldsymbol{ \epsilon}}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\normalizedLaplacianMatrix}{\hat{\mathbf{L}}}
\newcommand{\normalizedLaplacianScalar}{\hat{\ell}}
\newcommand{\normalizedLaplacianVector}{\hat{\mathbf{ \ell}}}
\newcommand{\numActive}{m}
\newcommand{\numBasisFunc}{m}
\newcommand{\numComponents}{m}
\newcommand{\numComps}{K}
\newcommand{\numData}{n}
\newcommand{\numFeatures}{K}
\newcommand{\numHidden}{h}
\newcommand{\numInducing}{m}
\newcommand{\numLayers}{\ell}
\newcommand{\numNeighbors}{K}
\newcommand{\numSequences}{s}
\newcommand{\numSuccess}{s}
\newcommand{\numTasks}{m}
\newcommand{\numTime}{T}
\newcommand{\numTrials}{S}
\newcommand{\outputIndex}{j}
\newcommand{\paramVector}{\boldsymbol{ \theta}}
\newcommand{\parameterMatrix}{\boldsymbol{ \Theta}}
\newcommand{\parameterScalar}{\theta}
\newcommand{\parameterVector}{\boldsymbol{ \parameterScalar}}
\newcommand{\partDiff}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\precisionScalar}{j}
\newcommand{\precisionVector}{\mathbf{ \precisionScalar}}
\newcommand{\precisionMatrix}{\mathbf{J}}
\newcommand{\pseudotargetScalar}{\widetilde{y}}
\newcommand{\pseudotargetVector}{\mathbf{ \pseudotargetScalar}}
\newcommand{\pseudotargetMatrix}{\mathbf{ \widetilde{Y}}}
\newcommand{\rank}[1]{\text{rank}\left(#1\right)}
\newcommand{\rayleighDist}[2]{\mathcal{R}\left(#1|#2\right)}
\newcommand{\rayleighSamp}[1]{\mathcal{R}\left(#1\right)}
\newcommand{\responsibility}{r}
\newcommand{\rotationScalar}{r}
\newcommand{\rotationVector}{\mathbf{ \rotationScalar}}
\newcommand{\rotationMatrix}{\mathbf{R}}
\newcommand{\sampleCovScalar}{s}
\newcommand{\sampleCovVector}{\mathbf{ \sampleCovScalar}}
\newcommand{\sampleCovMatrix}{\mathbf{s}}
\newcommand{\scalarProduct}[2]{\left\langle{#1},{#2}\right\rangle}
\newcommand{\sign}[1]{\text{sign}\left(#1\right)}
\newcommand{\sigmoid}[1]{\sigma\left(#1\right)}
\newcommand{\singularvalue}{\ell}
\newcommand{\singularvalueMatrix}{\mathbf{L}}
\newcommand{\singularvalueVector}{\mathbf{l}}
\newcommand{\sorth}{\mathbf{u}}
\newcommand{\spar}{\lambda}
\newcommand{\trace}[1]{\text{tr}\left(#1\right)}
\newcommand{\BasalRate}{B}
\newcommand{\DampingCoefficient}{C}
\newcommand{\DecayRate}{D}
\newcommand{\Displacement}{X}
\newcommand{\LatentForce}{F}
\newcommand{\Mass}{M}
\newcommand{\Sensitivity}{S}
\newcommand{\basalRate}{b}
\newcommand{\dampingCoefficient}{c}
\newcommand{\mass}{m}
\newcommand{\sensitivity}{s}
\newcommand{\springScalar}{\kappa}
\newcommand{\springVector}{\boldsymbol{ \kappa}}
\newcommand{\springMatrix}{\boldsymbol{ \mathcal{K}}}
\newcommand{\tfConcentration}{p}
\newcommand{\tfDecayRate}{\delta}
\newcommand{\tfMrnaConcentration}{f}
\newcommand{\tfVector}{\mathbf{ \tfConcentration}}
\newcommand{\velocity}{v}
\newcommand{\sufficientStatsScalar}{g}
\newcommand{\sufficientStatsVector}{\mathbf{ \sufficientStatsScalar}}
\newcommand{\sufficientStatsMatrix}{\mathbf{G}}
\newcommand{\switchScalar}{s}
\newcommand{\switchVector}{\mathbf{ \switchScalar}}
\newcommand{\switchMatrix}{\mathbf{S}}
\newcommand{\tr}[1]{\text{tr}\left(#1\right)}
\newcommand{\loneNorm}[1]{\left\Vert #1 \right\Vert_1}
\newcommand{\ltwoNorm}[1]{\left\Vert #1 \right\Vert_2}
\newcommand{\onenorm}[1]{\left\vert#1\right\vert_1}
\newcommand{\twonorm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\vScalar}{v}
\newcommand{\vVector}{\mathbf{v}}
\newcommand{\vMatrix}{\mathbf{V}}
\newcommand{\varianceDist}[2]{\text{var}_{#2}\left( #1 \right)}
% Already defined by latex
%\newcommand{\vec}{#1:}
\newcommand{\vecb}[1]{\left(#1\right):}
\newcommand{\weightScalar}{w}
\newcommand{\weightVector}{\mathbf{ \weightScalar}}
\newcommand{\weightMatrix}{\mathbf{W}}
\newcommand{\weightedAdjacencyMatrix}{\mathbf{A}}
\newcommand{\weightedAdjacencyScalar}{a}
\newcommand{\weightedAdjacencyVector}{\mathbf{ \weightedAdjacencyScalar}}
\newcommand{\onesVector}{\mathbf{1}}
\newcommand{\zerosVector}{\mathbf{0}}
\]
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Data Science and Digital Systems</h1>
  <p class="subtitle" style="text-align:center">The Three Ds of ML Systems Design</p>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2019-02-19</time></p>
  <p class="venue" style="text-align:center">Stu Hunter Resesearch Conference, Milan</p>
</section>

<section class="slide level3">

<!-- Front matter -->
<!--Back matter-->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!-- SECTION Introduction -->
<p><span style="text-align:right"></span></p>
</section>
<section id="the-gartner-hype-cycle" class="slide level3">
<h3>The Gartner Hype Cycle</h3>
<div style="width:60%">
<object class="svgplot " align data="../slides/diagrams/Gartner_Hype_Cycle.svg" style="vertical-align:middle;">
</object>
</div>
<p><span style="text-align:right"></span></p>
</section>
<section id="gartner-hype-cycle" class="slide level3">
<h3>Gartner Hype Cycle</h3>
<script>
showDivs(0, 'ai-bd-dm-dl-ml-google-trends');
</script>
<small></small> <input id="range-ai-bd-dm-dl-ml-google-trends" type="range" min="0" max="4" value="0" onchange="setDivs('ai-bd-dm-dl-ml-google-trends')" oninput="setDivs('ai-bd-dm-dl-ml-google-trends')">
<button onclick="plusDivs(-1, 'ai-bd-dm-dl-ml-google-trends')">
❮
</button>
<button onclick="plusDivs(1, 'ai-bd-dm-dl-ml-google-trends')">
❯
</button>
<div class="ai-bd-dm-dl-ml-google-trends" style="text-align:center;max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/ai-bd-dm-dl-ml-google-trends000.svg" style="vertical-align:middle;">
</object>
</div>
<div class="ai-bd-dm-dl-ml-google-trends" style="text-align:center;max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/ai-bd-dm-dl-ml-google-trends001.svg" style="vertical-align:middle;">
</object>
</div>
<div class="ai-bd-dm-dl-ml-google-trends" style="text-align:center;max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/ai-bd-dm-dl-ml-google-trends002.svg" style="vertical-align:middle;">
</object>
</div>
<div class="ai-bd-dm-dl-ml-google-trends" style="text-align:center;max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/ai-bd-dm-dl-ml-google-trends003.svg" style="vertical-align:middle;">
</object>
</div>
<div class="ai-bd-dm-dl-ml-google-trends" style="text-align:center;max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/ai-bd-dm-dl-ml-google-trends004.svg" style="vertical-align:middle;">
</object>
</div>
<div class="ai-bd-dm-dl-ml-google-trends" style="text-align:center;max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/ai-bd-dm-dl-ml-google-trends.svg" style="vertical-align:middle;">
</object>
</div>
<p><span style="text-align:right"></span></p>
</section>
<section id="section" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/science-holborn-viaduct.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-1" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/SteamEngine_Boulton&Watt_1784.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-2" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/Centrifugal_governor.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<!-- SECTION Machine Learning, Artificial Intelligence and Data Science -->
<p><span style="text-align:right"></span></p>
</section>
<section id="section-3" class="slide level3">
<h3></h3>
<p><span class="math display">\[\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}\]</span></p>
</section>
<section id="section-4" class="slide level3">
<h3></h3>
<table>
<tr>
<td width="35%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/earth_PNG37.png" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="45%">
<span class="math display">\[\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}\]</span>
</td>
<td width="20%">
<object class="svgplot " align data="../slides/diagrams/ai/1969018.svg" style="vertical-align:middle;">
</object>
</td>
</tr>
</table>
<p><span style="text-align:right"></span></p>
</section>
<section id="artificial-intelligence-and-data-science" class="slide level3">
<h3>Artificial Intelligence and Data Science</h3>
<ul>
<li>AI aims to equip computers with human capabilities
<ul>
<li>Image understanding</li>
<li>Computer vision</li>
<li>Speech recognition</li>
<li>Natural language understanding</li>
<li>Machine translation</li>
</ul></li>
</ul>

<ul>
<li>Dominant approach today:
<ul>
<li>Generate large labelled data set from humans.</li>
<li>Use <em>supervised learning</em> to emulate that data.
<ul>
<li><em>E.g.</em> <a href="www.image-net.org">ImageNet</a> <span class="citation" data-cites="Russakovsky-imagenet15">Russakovsky et al. (2015)</span></li>
</ul></li>
</ul></li>
<li>Significant advances due to <em>deep learning</em>
<ul>
<li><em>E.g.</em> Alexa, Amazon Go</li>
</ul></li>
</ul>
</section>
<section id="data-science" class="slide level3">
<h3>Data Science</h3>
<ul>
<li>Arises from <em>happenstance data</em>.</li>
<li>Differs from statistics in that the question comes <em>after</em> data collection.</li>
</ul>
<!-- SECTION Human Intelligence -->
<p><span style="text-align:right"></span></p>
<p><span style="text-align:right"></span></p>
</section>
<section id="embodiment-factors" class="slide level3">
<h3>“Embodiment Factors”</h3>
<p> See <span class="citation" data-cites="Lawrence:embodiment17">(“Living Together: Mind and Machine Intelligence” Lawrence, 2017a)</span>(https://arxiv.org/abs/1705.07996)</p>
</section>
<section id="section-5" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Lotus_49-2.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-6" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/640px-Marcel_Renault_1903.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-7" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Caleb_McDuff_WIX_Silence_Racing_livery.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><span style="text-align:right"></span></p>
<!-- SECTION Evolved Relationship with Information -->
</section>
<section id="evolved-relationship" class="slide level3">
<h3>Evolved Relationship</h3>
<div class="new-flow-of-information" style="max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/new-flow-of-information001.svg" style="vertical-align:middle;height:50%">
</object>
</div>
</section>
<section id="evolved-relationship-1" class="slide level3">
<h3>Evolved Relationship</h3>
<div class="new-flow-of-information" style="max-width:100vw; max-height:100vh">
<object class="svgplot " align data="../slides/diagrams/data-science/new-flow-of-information002.svg" style="vertical-align:middle;height:50%">
</object>
</div>
</section>
<section id="a-definition-of-intelligence" class="slide level3">
<h3>A Definition of Intelligence</h3>
<p><span style="text-align:right"></span></p>
</section>
<section id="what-does-machine-learning-do" class="slide level3">
<h3>What does Machine Learning do?</h3>
<ul>
<li>Automation scales by codifying processes and automating them.</li>
<li>Need:
<ul>
<li>Interconnected components</li>
<li>Compatible components</li>
</ul></li>
<li>Early examples:
<ul>
<li>cf Colt 45, Ford Model T</li>
</ul></li>
</ul>
</section>
<section id="codify-through-mathematical-functions" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ \text{odds} = \frac{p(\text{bought})}{p(\text{not bought})} \]</span> <span class="math display">\[ \log \text{odds}  = \beta_0 + \beta_1 \text{age} + \beta_2 \text{latitude}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-1" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ p(\text{bought}) =  \sigmoid{\beta_0 + \beta_1 \text{age} + \beta_2 \text{latitude}}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-2" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ p(\text{bought}) =  \sigmoid{\boldsymbol{\beta}^\top \inputVector}.\]</span></p>
</section>
<section id="codify-through-mathematical-functions-3" class="slide level3">
<h3>Codify Through Mathematical Functions</h3>
<ul>
<li>How does machine learning work?</li>
<li>Jumper (jersey/sweater) purchase with logistic regression</li>
</ul>
<p><span class="math display">\[ \dataScalar =  \mappingFunction\left(\inputVector, \boldsymbol{\beta}\right).\]</span></p>
<div class="fragment">
<p>We call <span class="math inline">\(\mappingFunction(\cdot)\)</span> the <em>prediction function</em>.</p>
</div>
</section>
<section id="fit-to-data" class="slide level3">
<h3>Fit to Data</h3>
<ul>
<li>Use an objective function</li>
</ul>
<p><span class="math display">\[\errorFunction(\boldsymbol{\beta}, \dataMatrix, \inputMatrix)\]</span></p>
<div class="fragment">
<ul>
<li>E.g. least squares <span class="math display">\[\errorFunction(\boldsymbol{\beta}, \dataMatrix, \inputMatrix) = \sum_{i=1}^\numData \left(\dataScalar_i - \mappingFunction(\inputVector_i, \boldsymbol{\beta})\right)^2.\]</span></li>
</ul>
</div>
</section>
<section id="two-components" class="slide level3">
<h3>Two Components</h3>
<ul>
<li>Prediction function, <span class="math inline">\(\mappingFunction(\cdot)\)</span></li>
<li>Objective function, <span class="math inline">\(\errorFunction(\cdot)\)</span></li>
</ul>
</section>
<section id="deep-learning" class="slide level3">
<h3>Deep Learning</h3>
<ul>
<li><p>These are interpretable models: vital for disease etc.</p></li>
<li><p>Modern machine learning methods are less interpretable</p></li>
<li><p>Example: face recognition</p></li>
</ul>
<p><span style="text-align:right"></span></p>
<!-- No slide titles in this context -->
<p><span style="text-align:right"></span></p>
</section>
<section id="section-8" class="slide level3">
<h3></h3>
<p><span class="fragment fade-in"><small>Outline of the DeepFace architecture. A front-end of a single convolution-pooling-convolution filtering on the rectified input, followed by three locally-connected layers and two fully-connected layers. Color illustrates feature maps produced at each layer. The net includes more than 120 million parameters, where more than 95% come from the local and fully connected.</small></span></p>
<div class="centered" style="">
<img class="" src="../slides/diagrams/deepface_neg.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><span style="text-align:right"><small>Source: DeepFace <span class="citation" data-cites="Taigman:deepface14">(Taigman et al., 2014)</span></small></span></p>
<p><span style="text-align:right"></span></p>
</section>
<section id="section-9" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/576px-Early_Pinball.jpg" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-10" class="slide level3">
<h3></h3>
<div style="text-align:center">
<object class="svgplot " align data="../slides/diagrams/pinball001.svg" style="vertical-align:middle;">
</object>
</div>
</section>
<section id="section-11" class="slide level3">
<h3></h3>
<div style="text-align:center">
<object class="svgplot " align data="../slides/diagrams/pinball002.svg" style="vertical-align:middle;">
</object>
</div>
<!-- SECTION Data Science and Professionalisation -->
<p><span style="text-align:right"></span></p>
</section>
<section id="data-science-1" class="slide level3">
<h3>Data Science</h3>
<ul>
<li>Industrial Revolution 4.0?</li>
<li><em>Industrial Revolution</em> (1760-1840) term coined by Arnold Toynbee, in 20th century.</li>
<li>Maybe: But this one is dominated by <em>data</em> not <em>capital</em></li>
<li>That presents <em>challenges</em> and <em>opportunities</em></li>
</ul>
<p>compare <a href="https://www.theguardian.com/media-network/2015/mar/05/digital-oligarchy-algorithms-personal-data">digital oligarchy</a> vs <a href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information">how Africa can benefit from the data revolution</a></p>
<ul>
<li>Apple vs Nokia: How you handle disruption.</li>
</ul>
</section>
<section id="a-time-for-professionalisation" class="slide level3">
<h3>A Time for Professionalisation?</h3>
<ul>
<li>New technologies historically led to new professions:
<ul>
<li>Brunel (born 1806): Civil, mechanical, naval</li>
<li>Tesla (born 1856): Electrical and power</li>
<li>William Shockley (born 1910): Electronic</li>
<li>Watts S. Humphrey (born 1927): Software</li>
</ul></li>
</ul>
</section>
<section id="why" class="slide level3">
<h3>Why?</h3>
<ul>
<li>Codification of best practice.</li>
<li>Developing trust</li>
</ul>
</section>
<section id="where-are-we" class="slide level3">
<h3>Where are we?</h3>
<ul>
<li>Perhaps around the 1980s of programming.
<ul>
<li>We understand <code>if</code>, <code>for</code>, and procedures</li>
<li>But we don’t share best practice.</li>
</ul></li>
<li>Let’s <em>avoid</em> the over formalisation of software engineering.</li>
</ul>
<p><span style="text-align:right"></span></p>
<!--
include{_data-science/includes/the-data-crisis.md} 

newslide{Rest of this Talk: Two Areas of Focus}

* Reusability of Data
* Deployment of Machine Learning Systems

newslide{Rest of this Talk: Two Areas of Focus}

* <s>Reusability of Data</s>
* Deployment of Machine Learning Systems

include{_data-science/includes/data-readiness-levels.md}


### Artificial Intelligence



* Challenges in deploying AI.
* Currently this is in the form of "machine learning systems"


### Internet of People



* Fog computing: barrier between cloud and device blurring.
    * Computing on the Edge
* Complex feedback between algorithm and implementation
  

### Deploying ML in Real World: Machine Learning Systems Design



* Major new challenge for systems designers.
* Internet of Intelligence but currently:
    * AI systems are *fragile*





-->
<!-- SECTION The Physical World: Where Bits meet Atoms -->
<p><span style="text-align:right"></span></p>
</section>
<section id="machine-learning-in-supply-chain" class="slide level3">
<h3>Machine Learning in Supply Chain</h3>
<ul>
<li><em>Supply chain</em>: Large Automated Decision Making Network</li>
<li>Amazon’s supply chain: Possibly the world’s largest ‘AI’</li>
<li>Major Challenge:
<ul>
<li>We have a <em>mechanistic</em> understanding of supply chain.</li>
<li>Machine learning is a <em>data driven</em> technology.</li>
</ul></li>
</ul>
<p><span style="text-align:right"></span></p>
</section>
<section id="the-tribal-mentality" class="slide level3">
<h3>The Tribal Mentality</h3>
<ul>
<li><span class="math inline">\(\text{data} + \text{model}\)</span> is <em>not</em> new.
<ul>
<li>Dates back to Newton, Laplace, Gauss</li>
</ul></li>
<li><em>Plethora</em> of fields: <em>E.g.</em>
<ul>
<li>Operations Research</li>
<li>Control</li>
<li>Econometrics</li>
<li>Statistics</li>
<li>Machine learning</li>
<li>Data science</li>
</ul></li>
</ul>
</section>
<section id="the-tribal-mentality-1" class="slide level3">
<h3>The Tribal Mentality</h3>
<ul>
<li>This can lead to confusion:
<ul>
<li>Different academic fields are:
<ul>
<li>Born in different eras</li>
<li>Driven by different motivations</li>
<li>Arrive at different solutions</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="tribalism-can-be-good" class="slide level3">
<h3>Tribalism Can be Good</h3>
<ul>
<li>Allows for consensus on best practice.</li>
<li>Shared set of goals</li>
<li>Ease of commiunication</li>
<li>Rapid deployment of robust solutions</li>
</ul>
</section>
<section id="professional-tribes" class="slide level3">
<h3>Professional Tribes</h3>
<ul>
<li>This is the nature of professions
<ul>
<li>lawyers</li>
<li>medics</li>
<li>doctors</li>
<li>engineers</li>
<li>accountants</li>
</ul></li>
</ul>
</section>
<section id="different-views" class="slide level3">
<h3>Different Views</h3>
<p><span class="math display">\[\text{data} + \text{model}\]</span></p>
<ul>
<li>For OR, control, stats etc.</li>
<li>More things <em>unite</em> us rather than <em>divide</em> us.</li>
</ul>
</section>
<section id="were-no-longer-hunter-gatherers" class="slide level3">
<h3>We’re no longer hunter gatherers …</h3>
<ul>
<li>The automation challenges we face require
<ul>
<li>all of our best ideas.</li>
<li>rethinking what <span class="math inline">\(\text{data}+\text{model}\)</span> means</li>
<li>rapid deployment and continuous monitoring</li>
</ul></li>
<li>This is the era of <em>data science</em></li>
</ul>
</section>
<section id="discomfort-and-disconformation" class="slide level3">
<h3>Discomfort and Disconformation</h3>
<ul>
<li>Talking across field boundaries is <em>critical</em>.</li>
<li>It helps us <em>disconfirm our beliefs</em>.</li>
<li>It’s not comfortable, but it’s vital.</li>
</ul>

<!-- SECTION The Three Ds of ML Systems Design -->
<p><span style="text-align:right"></span></p>
<p><span style="text-align:right"></span></p>
</section>
<section id="the-three-ds-of-machine-learning-systems-design" class="slide level3">
<h3>The Three Ds of Machine Learning Systems Design</h3>
<ul>
<li>Three primary challenges of Machine Learning Systems Design.</li>
</ul>
<ol type="1">
<li>Decomposition</li>
<li>Data</li>
<li>Deployment</li>
</ol>
<p><span style="text-align:right"></span></p>
</section>
<section id="decomposition" class="slide level3">
<h3>Decomposition</h3>
<ul>
<li>ML is not Magical Pixie Dust.</li>
<li>It cannot be sprinkled thoughtlessly.</li>
<li>We cannot simply <em>automate all decisions through data</em></li>
</ul>
</section>
<section id="decomposition-1" class="slide level3">
<h3>Decomposition</h3>
<p>We are constrained by:</p>
<ol type="1">
<li>Our <em>data</em>.</li>
<li>The <em>models</em>.</li>
</ol>
</section>
<section id="decomposition-of-task" class="slide level3">
<h3>Decomposition of Task</h3>
<ul>
<li>Careful thought needs to be put into sub-processes of task.</li>
<li>Any repetitive task is a candidate for automation.</li>
</ul>

<div class="centered centered" style="">
<img class="" src="../slides/diagrams/TooManyPigeons.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="pigeonholing-1" class="slide level3">
<h3>Pigeonholing</h3>
<ol type="1">
<li>Can we decompose decision we need to repetitive sub-tasks where inputs and outputs are well defined?</li>
<li>Are those repetitive sub-tasks well represent by a mathematical mapping?</li>
</ol>
</section>
<section id="a-trap" class="slide level3">
<h3>A Trap</h3>
<ul>
<li>Over emphasis on the <em>type</em> of model we’re deploying.</li>
<li>Under emphasis on the appropriateness of the task decomposition.</li>
</ul>
</section>
<section id="chicken-and-egg" class="slide level3">
<h3>Chicken and Egg</h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/chicken-and-egg.jpg" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="co-evolution" class="slide level3">
<h3>Co-evolution</h3>
<ul>
<li>Absolute decomposition is impossible.</li>
<li>If we deploy a weak component in one place, downstream system will compensate.</li>
<li>Systems <em>co-evolve</em> … there is no <em>simple</em> solution</li>
<li>Trade off between <em>performance</em> and <em>decomposability</em>.
<ul>
<li>Need to monitor deployment</li>
</ul></li>
</ul>
<p><span style="text-align:right"></span></p>
</section>
<section id="data" class="slide level3">
<h3>Data</h3>
<ul>
<li>Hard to overstate its importance.</li>
<li>Half the equation of <span class="math inline">\(\text{data} + \text{model}\)</span>.</li>
<li>Often utterly neglected.</li>
</ul>
</section>
<section id="data-neglect" class="slide level3">
<h3>Data Neglect</h3>
<ul>
<li>Arises for two reasons.
<ol type="1">
<li>Data cleaning is perceived as tedious.</li>
<li>Data cleaning is complex.</li>
</ol></li>
</ul>
</section>
<section id="data-cleaning" class="slide level3">
<h3>Data Cleaning</h3>
<ul>
<li>Seems difficult to formulate into readily teachable princples.</li>
<li>Heavily neglected in data science, statistics and ML courses.</li>
<li>In practice most scientists spend around 80% of time data cleaning.</li>
</ul>
</section>
<section id="the-data-crisis" class="slide level3">
<h3>The Data Crisis</h3>
<p><span style="text-align:right"></span></p>

<p><small></p>
<blockquote>
<p>The major cause of the software crisis is that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming has become an equally gigantic problem.</p>
<p>Edsger Dijkstra (1930-2002), The Humble Programmer</p>
</blockquote>
<p></small></p>
</section>
<section id="the-data-crisis-1" class="slide level3">
<h3>The Data Crisis</h3>
<p><small></p>
<blockquote>
<p>The major cause of the data crisis is that machines have become more interconnected than ever before. Data access is therefore cheap, but data quality is often poor. What we need is cheap high quality data. That implies that we develop processes for improving and verifying data quality that are efficient.</p>
<p>There would seem to be two ways for improving efficiency. Firstly, we should not duplicate work. Secondly, where possible we should automate work.</p>
<p>Me </small></p>
</blockquote>



<p><span style="text-align:right"></span></p>
</section>
<section id="section-12" class="slide level3">
<h3></h3>
<div class="centered" style="">
<img class="" src="../slides/diagrams/data-science/data-readiness-levels.png" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><a href="https://arxiv.org/pdf/1705.02245.pdf" class="uri">https://arxiv.org/pdf/1705.02245.pdf</a> <a href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data Readiness Levels</a> <span class="citation" data-cites="Lawrence:drl17">(Lawrence, 2017b)</span></p>
</section>
<section id="three-grades-of-data-readiness" class="slide level3">
<h3>Three Grades of Data Readiness</h3>
<ul>
<li><p>Grade C - accessibility</p></li>
<li><p>Grade B - validity</p></li>
<li><p>Grade A - usability</p></li>
</ul>

<p><span style="text-align:right"></span></p>
</section>
<section id="data-science-as-debugging" class="slide level3">
<h3>Data Science as Debugging</h3>
<ul>
<li>Analogies: For Software Engineers <a href="http://inverseprobability.com/2017/03/14/data-science-as-debugging">describe data science as <em>debugging</em></a>.</li>
</ul>
</section>
<section id="section-13" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/data-science/water-bridge-hill-transport-arch-calm-544448-pxhere.com.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="section-14" class="slide level3">
<h3></h3>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/data-science/1024px-Lake_District_picture.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p><span style="text-align:right"></span></p>
</section>
<section id="deployment" class="slide level3">
<h3>Deployment</h3>
</section>
<section id="premise" class="slide level3">
<h3>Premise</h3>
<p>Our <em>machine learning</em> is based on a <em>software systems</em> view that is 20 years out of date.</p>

<ul>
<li>Deployment of modeling code.</li>
<li>Data dependent models in production need <em>continuous monitoring</em>.</li>
</ul>
</section>
<section id="continuous-monitoring" class="slide level3">
<h3>Continuous Monitoring</h3>
<ul>
<li>Continuous deployment:
<ul>
<li>We’ve changed the code, we should test the effect.</li>
</ul></li>
<li>Continuous Monitoring:
<ul>
<li>The world around us is changing, we should monitor the effect.</li>
</ul></li>
<li>Update our notions of testing: <em>progression testing</em></li>
</ul>
</section>
<section id="data-orientated-architectures" class="slide level3">
<h3>Data Orientated Architectures</h3>
<ul>
<li>Historically we’ve been <em>software first</em>
<ul>
<li>A necessary but not sufficient condition for <em>data first</em></li>
</ul></li>
<li>Move from
<ol type="1">
<li>software orientated architectures</li>
<li><em>data orientated architectures</em></li>
</ol></li>
</ul>
</section>
<section id="streaming-architectures" class="slide level3">
<h3>Streaming Architectures</h3>
<ul>
<li>AWS Kinesis, Apache Kafka</li>
<li>Not just about streaming
<ul>
<li>Nodes in the architecture are <em>stateless</em></li>
<li>They persist through storing state on <em>streams</em></li>
</ul></li>
<li>This brings the data <em>inside out</em></li>
</ul>
</section>
<section id="outlook-for-machine-learning" class="slide level3">
<h3>Outlook for Machine Learning</h3>
<ul>
<li>Risen to prominence to <em>scale</em> our activities.</li>
<li>To scale activities need more computer based automation.</li>
<li>Machine learning allows us to automate processes previously out of reach.</li>
</ul>
<!-- SECTION Conclusion -->
</section>
<section id="conclusion" class="slide level3">
<h3>Conclusion</h3>
<ul>
<li>Technologically <em>evolving</em> environment.</li>
<li>ML is a key component of decision making.</li>
<li>Data is the key component of ML.</li>
<li>ML is <em>critically</em> dependent on data.</li>
<li>Challenges in <em>problem Decomposition</em>, <em>Data curation</em> and <em>model Deployment</em></li>
</ul>
</section>
<section id="thanks" class="slide level3">
<h3>Thanks!</h3>
<ul>
<li>twitter: @lawrennd</li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
<li>podcast: <a href="http://thetalkingmachines.com" class="uri">http://thetalkingmachines.com</a></li>
<li><a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural vs Artifical Intelligence</a></li>
<li><a href="https://medium.com/@mijordan3/artificial-intelligence-the-revolution-hasnt-happened-yet-5e1d5812e1e7">Mike Jordan’s Medium Post</a></li>
</ul>
</section>
<section id="references" class="slide level3 unnumbered">
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Lawrence:embodiment17">
<p>Lawrence, N.D., 2017a. Living together: Mind and machine intelligence. arXiv.</p>
</div>
<div id="ref-Lawrence:drl17">
<p>Lawrence, N.D., 2017b. Data readiness levels. arXiv.</p>
</div>
<div id="ref-Russakovsky-imagenet15">
<p>Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115, 211–252. <a href="https://doi.org/10.1007/s11263-015-0816-y" class="uri">https://doi.org/10.1007/s11263-015-0816-y</a></p>
</div>
<div id="ref-Taigman:deepface14">
<p>Taigman, Y., Yang, M., Ranzato, M., Wolf, L., 2014. DeepFace: Closing the gap to human-level performance in face verification, in: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. <a href="https://doi.org/10.1109/CVPR.2014.220" class="uri">https://doi.org/10.1109/CVPR.2014.220</a></p>
</div>
</div>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
